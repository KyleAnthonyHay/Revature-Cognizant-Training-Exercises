{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90d738de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: chromadb 0.3.23\n",
      "Uninstalling chromadb-0.3.23:\n",
      "  Successfully uninstalled chromadb-0.3.23\n",
      "Found existing installation: pydantic 2.12.5\n",
      "Uninstalling pydantic-2.12.5:\n",
      "  Successfully uninstalled pydantic-2.12.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting chromadb\n",
      "  Using cached chromadb-1.4.0-cp39-abi3-macosx_11_0_arm64.whl.metadata (7.2 kB)\n",
      "Collecting pydantic\n",
      "  Using cached pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\n",
      "Collecting pydantic-settings\n",
      "  Using cached pydantic_settings-2.12.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting build>=1.0.3 (from chromadb)\n",
      "  Using cached build-1.3.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting pybase64>=1.4.1 (from chromadb)\n",
      "  Using cached pybase64-1.4.3-cp314-cp314-macosx_11_0_arm64.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/.venv/lib/python3.14/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.40.0)\n",
      "Requirement already satisfied: numpy>=1.22.5 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/.venv/lib/python3.14/site-packages (from chromadb) (2.4.0)\n",
      "Collecting posthog<6.0.0,>=2.4.0 (from chromadb)\n",
      "  Using cached posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/.venv/lib/python3.14/site-packages (from chromadb) (4.15.0)\n",
      "INFO: pip is looking at multiple versions of chromadb to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting chromadb\n",
      "  Using cached chromadb-1.3.7-cp39-abi3-macosx_11_0_arm64.whl.metadata (7.2 kB)\n",
      "  Using cached chromadb-1.3.6-cp39-abi3-macosx_11_0_arm64.whl.metadata (7.2 kB)\n",
      "  Using cached chromadb-1.3.5-cp39-abi3-macosx_11_0_arm64.whl.metadata (7.2 kB)\n",
      "  Using cached chromadb-1.3.4-cp39-abi3-macosx_11_0_arm64.whl.metadata (7.2 kB)\n",
      "  Using cached chromadb-1.3.3-cp39-abi3-macosx_11_0_arm64.whl.metadata (7.2 kB)\n",
      "  Using cached chromadb-1.3.2-cp39-abi3-macosx_11_0_arm64.whl.metadata (7.2 kB)\n",
      "  Using cached chromadb-1.3.0-cp39-abi3-macosx_11_0_arm64.whl.metadata (7.2 kB)\n",
      "INFO: pip is still looking at multiple versions of chromadb to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached chromadb-1.2.2-cp39-abi3-macosx_11_0_arm64.whl.metadata (7.2 kB)\n",
      "  Using cached chromadb-1.2.1-cp39-abi3-macosx_11_0_arm64.whl.metadata (7.2 kB)\n",
      "  Using cached chromadb-1.2.0-cp39-abi3-macosx_11_0_arm64.whl.metadata (7.2 kB)\n",
      "  Using cached chromadb-1.1.1-cp39-abi3-macosx_11_0_arm64.whl.metadata (7.2 kB)\n",
      "  Using cached chromadb-1.1.0-cp39-abi3-macosx_11_0_arm64.whl.metadata (7.2 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached chromadb-1.0.21-cp39-abi3-macosx_11_0_arm64.whl.metadata (7.3 kB)\n",
      "  Using cached chromadb-1.0.20-cp39-abi3-macosx_11_0_arm64.whl.metadata (7.3 kB)\n",
      "  Using cached chromadb-1.0.19-cp39-abi3-macosx_11_0_arm64.whl.metadata (7.3 kB)\n",
      "  Using cached chromadb-1.0.18-cp39-abi3-macosx_11_0_arm64.whl.metadata (7.3 kB)\n",
      "  Using cached chromadb-1.0.17-cp39-abi3-macosx_11_0_arm64.whl.metadata (7.3 kB)\n",
      "  Using cached chromadb-1.0.16-cp39-abi3-macosx_11_0_arm64.whl.metadata (7.4 kB)\n",
      "  Using cached chromadb-1.0.15-cp39-abi3-macosx_11_0_arm64.whl.metadata (7.0 kB)\n",
      "  Using cached chromadb-1.0.13-cp39-abi3-macosx_11_0_arm64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/.venv/lib/python3.14/site-packages (from chromadb) (7.5.0)\n",
      "  Using cached chromadb-1.0.12-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.9 kB)\n",
      "Collecting fastapi==0.115.9 (from chromadb)\n",
      "  Using cached fastapi-0.115.9-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting chromadb\n",
      "  Using cached chromadb-1.0.11-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.9 kB)\n",
      "  Using cached chromadb-1.0.10-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.9 kB)\n",
      "  Using cached chromadb-1.0.9-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.9 kB)\n",
      "  Using cached chromadb-1.0.8-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.9 kB)\n",
      "  Using cached chromadb-1.0.7-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.9 kB)\n",
      "Collecting chroma-hnswlib==0.7.6 (from chromadb)\n",
      "  Using cached chroma_hnswlib-0.7.6.tar.gz (32 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting chromadb\n",
      "  Using cached chromadb-1.0.6-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.9 kB)\n",
      "  Using cached chromadb-1.0.5-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.9 kB)\n",
      "  Using cached chromadb-1.0.4-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.9 kB)\n",
      "  Using cached chromadb-1.0.3-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.9 kB)\n",
      "  Using cached chromadb-1.0.2-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.9 kB)\n",
      "  Using cached chromadb-1.0.0-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.9 kB)\n",
      "  Using cached chromadb-0.6.3-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/.venv/lib/python3.14/site-packages (from chromadb) (0.128.0)\n",
      "  Using cached chromadb-0.6.2-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Using cached chromadb-0.6.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Using cached chromadb-0.6.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Using cached chromadb-0.5.23-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Using cached chromadb-0.5.21-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Using cached chromadb-0.5.20-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Using cached chromadb-0.5.18-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Using cached chromadb-0.5.17-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Using cached chromadb-0.5.16-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Using cached chromadb-0.5.15-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Using cached chromadb-0.5.13-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Using cached chromadb-0.5.12-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Using cached chromadb-0.5.11-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Using cached chromadb-0.5.10-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Using cached chromadb-0.5.9-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Using cached chromadb-0.5.7-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Using cached chromadb-0.5.5-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting numpy<2.0.0,>=1.22.5 (from chromadb)\n",
      "  Using cached numpy-1.26.4.tar.gz (15.8 MB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting chromadb\n",
      "  Using cached chromadb-0.5.4-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting chroma-hnswlib==0.7.5 (from chromadb)\n",
      "  Using cached chroma_hnswlib-0.7.5.tar.gz (32 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting chromadb\n",
      "  Using cached chromadb-0.5.3-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: requests>=2.28 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/.venv/lib/python3.14/site-packages (from chromadb) (2.32.5)\n",
      "Collecting chroma-hnswlib==0.7.3 (from chromadb)\n",
      "  Using cached chroma-hnswlib-0.7.3.tar.gz (31 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting chromadb\n",
      "  Using cached chromadb-0.5.2-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Using cached chromadb-0.5.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Using cached chromadb-0.5.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "  Using cached chromadb-0.4.24-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting pulsar-client>=3.1.0 (from chromadb)\n",
      "  Using cached pulsar_client-3.9.0-cp314-cp314-macosx_13_0_universal2.whl.metadata (1.1 kB)\n",
      "Collecting chromadb\n",
      "  Using cached chromadb-0.4.23-py3-none-any.whl.metadata (7.3 kB)\n",
      "  Using cached chromadb-0.4.22-py3-none-any.whl.metadata (7.3 kB)\n",
      "  Using cached chromadb-0.4.21-py3-none-any.whl.metadata (7.3 kB)\n",
      "  Using cached chromadb-0.4.20-py3-none-any.whl.metadata (7.3 kB)\n",
      "  Using cached chromadb-0.4.19-py3-none-any.whl.metadata (7.3 kB)\n",
      "  Using cached chromadb-0.4.18-py3-none-any.whl.metadata (7.4 kB)\n",
      "  Using cached chromadb-0.4.17-py3-none-any.whl.metadata (7.3 kB)\n",
      "  Using cached chromadb-0.4.16-py3-none-any.whl.metadata (7.3 kB)\n",
      "  Using cached chromadb-0.4.15-py3-none-any.whl.metadata (7.2 kB)\n",
      "  Using cached chromadb-0.4.14-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Using cached chromadb-0.4.13-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Using cached chromadb-0.4.12-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting pydantic\n",
      "  Using cached pydantic-1.10.26-cp314-cp314-macosx_11_0_arm64.whl.metadata (155 kB)\n",
      "Collecting fastapi<0.100.0,>=0.95.2 (from chromadb)\n",
      "  Using cached fastapi-0.99.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting chromadb\n",
      "  Using cached chromadb-0.4.11-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Using cached chromadb-0.4.10-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Using cached chromadb-0.4.9-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting chroma-hnswlib==0.7.2 (from chromadb)\n",
      "  Using cached chroma-hnswlib-0.7.2.tar.gz (31 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting chromadb\n",
      "  Using cached chromadb-0.4.8-py3-none-any.whl.metadata (6.9 kB)\n",
      "  Using cached chromadb-0.4.7-py3-none-any.whl.metadata (6.9 kB)\n",
      "  Using cached chromadb-0.4.6-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Using cached chromadb-0.4.5-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Using cached chromadb-0.4.4-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Using cached chromadb-0.4.3-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pandas>=1.3 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/.venv/lib/python3.14/site-packages (from chromadb) (2.3.3)\n",
      "Collecting chroma-hnswlib==0.7.1 (from chromadb)\n",
      "  Using cached chroma-hnswlib-0.7.1.tar.gz (30 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting chromadb\n",
      "  Using cached chromadb-0.4.2-py3-none-any.whl.metadata (6.9 kB)\n",
      "  Using cached chromadb-0.4.1-py3-none-any.whl.metadata (6.9 kB)\n",
      "  Using cached chromadb-0.4.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "  Using cached chromadb-0.3.29-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: hnswlib>=0.7 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/.venv/lib/python3.14/site-packages (from chromadb) (0.8.0)\n",
      "Requirement already satisfied: clickhouse-connect>=0.5.7 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/.venv/lib/python3.14/site-packages (from chromadb) (0.10.0)\n",
      "Requirement already satisfied: duckdb>=0.7.1 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/.venv/lib/python3.14/site-packages (from chromadb) (1.4.3)\n",
      "Collecting fastapi==0.85.1 (from chromadb)\n",
      "  Using cached fastapi-0.85.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting chromadb\n",
      "  Using cached chromadb-0.3.27-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting pydantic\n",
      "  Using cached pydantic-1.9.0-py3-none-any.whl.metadata (121 kB)\n",
      "Collecting chromadb\n",
      "  Using cached chromadb-0.3.26-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Using cached chromadb-0.3.25-py3-none-any.whl.metadata (6.7 kB)\n",
      "  Using cached chromadb-0.3.23-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: sentence-transformers>=2.2.2 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/.venv/lib/python3.14/site-packages (from chromadb) (5.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/.venv/lib/python3.14/site-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/.venv/lib/python3.14/site-packages (from pydantic) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/.venv/lib/python3.14/site-packages (from pydantic) (0.4.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/.venv/lib/python3.14/site-packages (from pydantic-settings) (1.2.1)\n",
      "Requirement already satisfied: certifi in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/.venv/lib/python3.14/site-packages (from clickhouse-connect>=0.5.7->chromadb) (2026.1.4)\n",
      "Requirement already satisfied: urllib3>=1.26 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/.venv/lib/python3.14/site-packages (from clickhouse-connect>=0.5.7->chromadb) (2.6.2)\n",
      "Requirement already satisfied: pytz in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/.venv/lib/python3.14/site-packages (from clickhouse-connect>=0.5.7->chromadb) (2025.2)\n",
      "Requirement already satisfied: zstandard>=0.25.0 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/.venv/lib/python3.14/site-packages (from clickhouse-connect>=0.5.7->chromadb) (0.25.0)\n",
      "Requirement already satisfied: lz4>=4.4.5 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/.venv/lib/python3.14/site-packages (from clickhouse-connect>=0.5.7->chromadb) (4.4.5)\n",
      "Requirement already satisfied: starlette<0.51.0,>=0.40.0 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/.venv/lib/python3.14/site-packages (from fastapi>=0.95.2->chromadb) (0.50.0)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/.venv/lib/python3.14/site-packages (from fastapi>=0.95.2->chromadb) (0.0.4)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/.venv/lib/python3.14/site-packages (from starlette<0.51.0,>=0.40.0->fastapi>=0.95.2->chromadb) (4.12.1)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/.venv/lib/python3.14/site-packages (from anyio<5,>=3.6.2->starlette<0.51.0,>=0.40.0->fastapi>=0.95.2->chromadb) (3.11)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/.venv/lib/python3.14/site-packages (from pandas>=1.3->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/.venv/lib/python3.14/site-packages (from pandas>=1.3->chromadb) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/.venv/lib/python3.14/site-packages (from posthog>=2.4.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/.venv/lib/python3.14/site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: distro>=1.5.0 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/.venv/lib/python3.14/site-packages (from posthog>=2.4.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/.venv/lib/python3.14/site-packages (from requests>=2.28->chromadb) (3.4.4)\n",
      "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/.venv/lib/python3.14/site-packages (from sentence-transformers>=2.2.2->chromadb) (4.57.3)\n",
      "Requirement already satisfied: tqdm in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/.venv/lib/python3.14/site-packages (from sentence-transformers>=2.2.2->chromadb) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/.venv/lib/python3.14/site-packages (from sentence-transformers>=2.2.2->chromadb) (2.9.1)\n",
      "Requirement already satisfied: scikit-learn in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/.venv/lib/python3.14/site-packages (from sentence-transformers>=2.2.2->chromadb) (1.8.0)\n",
      "Requirement already satisfied: scipy in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/.venv/lib/python3.14/site-packages (from sentence-transformers>=2.2.2->chromadb) (1.16.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/.venv/lib/python3.14/site-packages (from sentence-transformers>=2.2.2->chromadb) (0.36.0)\n",
      "Requirement already satisfied: filelock in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/.venv/lib/python3.14/site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers>=2.2.2->chromadb) (3.20.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/.venv/lib/python3.14/site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers>=2.2.2->chromadb) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/.venv/lib/python3.14/site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers>=2.2.2->chromadb) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/.venv/lib/python3.14/site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers>=2.2.2->chromadb) (2025.11.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/.venv/lib/python3.14/site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers>=2.2.2->chromadb) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/.venv/lib/python3.14/site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers>=2.2.2->chromadb) (0.7.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/.venv/lib/python3.14/site-packages (from huggingface-hub>=0.20.0->sentence-transformers>=2.2.2->chromadb) (2025.12.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/.venv/lib/python3.14/site-packages (from huggingface-hub>=0.20.0->sentence-transformers>=2.2.2->chromadb) (1.2.0)\n",
      "Requirement already satisfied: setuptools in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/.venv/lib/python3.14/site-packages (from torch>=1.11.0->sentence-transformers>=2.2.2->chromadb) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/.venv/lib/python3.14/site-packages (from torch>=1.11.0->sentence-transformers>=2.2.2->chromadb) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/.venv/lib/python3.14/site-packages (from torch>=1.11.0->sentence-transformers>=2.2.2->chromadb) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/.venv/lib/python3.14/site-packages (from torch>=1.11.0->sentence-transformers>=2.2.2->chromadb) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/.venv/lib/python3.14/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers>=2.2.2->chromadb) (1.3.0)\n",
      "Requirement already satisfied: click>=7.0 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/.venv/lib/python3.14/site-packages (from uvicorn>=0.18.3->uvicorn[standard]>=0.18.3->chromadb) (8.3.1)\n",
      "Requirement already satisfied: h11>=0.8 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/.venv/lib/python3.14/site-packages (from uvicorn>=0.18.3->uvicorn[standard]>=0.18.3->chromadb) (0.16.0)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/.venv/lib/python3.14/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.7.1)\n",
      "Requirement already satisfied: uvloop>=0.15.1 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/.venv/lib/python3.14/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.22.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/.venv/lib/python3.14/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n",
      "Requirement already satisfied: websockets>=10.4 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/.venv/lib/python3.14/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/.venv/lib/python3.14/site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.2.2->chromadb) (3.0.3)\n",
      "Requirement already satisfied: joblib>=1.3.0 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/.venv/lib/python3.14/site-packages (from scikit-learn->sentence-transformers>=2.2.2->chromadb) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/.venv/lib/python3.14/site-packages (from scikit-learn->sentence-transformers>=2.2.2->chromadb) (3.6.0)\n",
      "Using cached chromadb-0.3.23-py3-none-any.whl (71 kB)\n",
      "Using cached pydantic-2.12.5-py3-none-any.whl (463 kB)\n",
      "Using cached pydantic_settings-2.12.0-py3-none-any.whl (51 kB)\n",
      "Installing collected packages: pydantic, pydantic-settings, chromadb\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [chromadb]1/3\u001b[0m [pydantic-settings]\n",
      "\u001b[1A\u001b[2KSuccessfully installed chromadb-0.3.23 pydantic-2.12.5 pydantic-settings-2.12.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip uninstall chromadb pydantic -y\n",
    "%pip install chromadb pydantic pydantic-settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "213dfddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: chromadb\n",
      "Version: 1.4.0\n",
      "Summary: Chroma.\n",
      "Home-page: https://github.com/chroma-core/chroma\n",
      "Author: \n",
      "Author-email: Jeff Huber <jeff@trychroma.com>, Anton Troynikov <anton@trychroma.com>\n",
      "License: \n",
      "Location: /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages\n",
      "Requires: bcrypt, build, grpcio, httpx, importlib-resources, jsonschema, kubernetes, mmh3, numpy, onnxruntime, opentelemetry-api, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-sdk, orjson, overrides, posthog, pybase64, pydantic, pypika, pyyaml, rich, tenacity, tokenizers, tqdm, typer, typing-extensions, uvicorn\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip show chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "554365e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Exercise 02: RAG Analysis\n",
      "============================================================\n",
      "[RAG] Added 6 documents\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Exercise 02: RAG Analysis - Starter Code\n",
    "\n",
    "Analyze RAG behavior and document observations.\n",
    "\n",
    "Prerequisites:\n",
    "- Completed Exercise 01\n",
    "\n",
    "This starter provides the RAG system for analysis.\n",
    "\"\"\"\n",
    "\n",
    "import chromadb\n",
    "\n",
    "# ============================================================================\n",
    "# SETUP - Pre-built RAG System for Analysis\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Exercise 02: RAG Analysis\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "\n",
    "class MockLLM:\n",
    "    \"\"\"Simple mock LLM for testing.\"\"\"\n",
    "    def generate(self, prompt):\n",
    "        if \"Context:\" in prompt and len(prompt) > 100:\n",
    "            context_start = prompt.find(\"Context:\") + 8\n",
    "            context_end = prompt.find(\"Question:\")\n",
    "            context = prompt[context_start:context_end].strip()\n",
    "            return f\"Based on the context: {context[:200]}...\"\n",
    "        return \"I don't have enough information to answer that.\"\n",
    "\n",
    "\n",
    "class SimpleRAG:\n",
    "    \"\"\"Pre-built RAG system for analysis exercises.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.client = chromadb.Client()\n",
    "        self.collection = self.client.create_collection(\"rag_analysis\")\n",
    "        self.llm = MockLLM()\n",
    "    \n",
    "    def add_knowledge(self, documents, ids=None):\n",
    "        if ids is None:\n",
    "            ids = [f\"doc_{i}\" for i in range(len(documents))]\n",
    "        self.collection.add(documents=documents, ids=ids)\n",
    "        print(f\"[RAG] Added {len(documents)} documents\")\n",
    "    \n",
    "    def query(self, question, k=3):\n",
    "        results = self.collection.query(\n",
    "            query_texts=[question], n_results=k,\n",
    "            include=[\"documents\", \"distances\"]\n",
    "        )\n",
    "        \n",
    "        context_docs = results['documents'][0]\n",
    "        distances = results['distances'][0]\n",
    "        \n",
    "        context = \"\\n\".join(context_docs)\n",
    "        prompt = f\"\"\"You are a helpful assistant. Answer based ONLY on the context.\n",
    "If context doesn't contain enough info, say \"I don't have enough information.\"\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "        \n",
    "        answer = self.llm.generate(prompt)\n",
    "        \n",
    "        return {\n",
    "            \"question\": question,\n",
    "            \"answer\": answer,\n",
    "            \"retrieved_docs\": context_docs,\n",
    "            \"distances\": distances,\n",
    "            \"num_sources\": len(context_docs)\n",
    "        }\n",
    "\n",
    "\n",
    "# Initialize RAG with knowledge base\n",
    "rag = SimpleRAG()\n",
    "rag.add_knowledge([\n",
    "    \"Python was created by Guido van Rossum and first released in 1991.\",\n",
    "    \"Machine learning enables systems to learn from experience without explicit programming.\",\n",
    "    \"Docker is a platform for running applications in containers.\",\n",
    "    \"REST is an architectural style using HTTP methods for networked applications.\",\n",
    "    \"Neural networks are computing systems inspired by biological brains.\",\n",
    "    \"Git is a version control system created by Linus Torvalds in 2005.\"\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28ca6045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Part 1: RAG Behavior Testing\n",
      "============================================================\n",
      "\n",
      "--- DIRECT MATCH ---\n",
      "Q: What year was Python released?\n",
      "A: Based on the context: Python was created by Guido van Rossum and first released in 1991.\n",
      "Git is a ve...\n",
      "Sources: [0.4295929968357086, 1.6448304653167725, 1.6890949010849]\n",
      "Q: What is REST?\n",
      "A: Based on the context: REST is an architectural style using HTTP methods for networked applications.\n",
      "...\n",
      "Sources: [0.7795387506484985, 1.6609597206115723, 1.8498444557189941]\n",
      "TODO: Test direct match questions\n",
      "\n",
      "--- SYNTHESIS REQUIRED ---\n",
      "TODO: Test synthesis questions\n",
      "\n",
      "Q: What are two programming languages mentioned and who created them?\n",
      "A: Based on the context: Python was created by Guido van Rossum and first released in 1991.\n",
      "Neural networks are computing systems inspired by biological ...\n",
      "Retrieved docs: ['Python was created by Guido van Rossum and first released in 1991.', 'Neural networks are computing systems inspired by biological brains.', 'REST is an architectural style using HTTP methods for networked applications.']\n",
      "Distances: [1.199242115020752, 1.5196928977966309, 1.6413617134094238]\n",
      "\n",
      "--- NO MATCH ---\n",
      "TODO: Test no-match questions\n",
      "\n",
      "Q: What is the capital of France?\n",
      "A: Based on the context: Python was created by Guido van Rossum and first released in 1991.\n",
      "Neural networks are computing systems inspired by biological ...\n",
      "Distances (higher = less relevant): [1.9095351696014404, 1.9156819581985474, 1.9555572271347046]\n",
      "\n",
      "Q: How do I make pizza?\n",
      "A: Based on the context: Python was created by Guido van Rossum and first released in 1991.\n",
      "Machine learning enables systems to learn from experience wit...\n",
      "Distances (higher = less relevant): [1.7579691410064697, 1.7607331275939941, 1.817023754119873]\n",
      "\n",
      "--- AMBIGUOUS ---\n",
      "TODO: Test ambiguous questions\n",
      "\n",
      "Q: Tell me about technology\n",
      "A: Based on the context: Neural networks are computing systems inspired by biological brains.\n",
      "REST is an architectural style using HTTP methods for netwo...\n",
      "Retrieved docs: ['Neural networks are computing systems inspired by biological brains.', 'REST is an architectural style using HTTP methods for networked applications.', 'Docker is a platform for running applications in containers.']\n",
      "Distances: [1.4916397333145142, 1.5804458856582642, 1.6582982540130615]\n",
      "\n",
      "Q: What programming tools should I use?\n",
      "A: Based on the context: Git is a version control system created by Linus Torvalds in 2005.\n",
      "Python was created by Guido van Rossum and first released in ...\n",
      "Retrieved docs: ['Git is a version control system created by Linus Torvalds in 2005.', 'Python was created by Guido van Rossum and first released in 1991.', 'Machine learning enables systems to learn from experience without explicit programming.']\n",
      "Distances: [1.4977630376815796, 1.5748828649520874, 1.6757162809371948]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# PART 1: RAG Behavior Testing\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Part 1: RAG Behavior Testing\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Direct Match Questions\n",
    "print(\"\\n--- DIRECT MATCH ---\")\n",
    "direct_questions = [\n",
    "    \"What year was Python released?\",\n",
    "    \"What is REST?\"\n",
    "]\n",
    "\n",
    "# TODO: Test each question and document results\n",
    "for q in direct_questions:\n",
    "    result = rag.query(q)\n",
    "    print(f\"Q: {q}\")\n",
    "    print(f\"A: {result['answer'][:100]}...\")\n",
    "    print(f\"Sources: {result['distances']}\")\n",
    "print(\"TODO: Test direct match questions\")\n",
    "\n",
    "\n",
    "# Synthesis Required\n",
    "print(\"\\n--- SYNTHESIS REQUIRED ---\")\n",
    "synthesis_questions = [\n",
    "    \"What are two programming languages mentioned and who created them?\"\n",
    "]\n",
    "print(\"TODO: Test synthesis questions\")\n",
    "for q in synthesis_questions:\n",
    "    result = rag.query(q)\n",
    "    print(f\"\\nQ: {q}\")\n",
    "    print(f\"A: {result['answer'][:150]}...\")\n",
    "    print(f\"Retrieved docs: {result['retrieved_docs']}\")\n",
    "    print(f\"Distances: {result['distances']}\")\n",
    "\n",
    "# No Match\n",
    "print(\"\\n--- NO MATCH ---\")\n",
    "no_match_questions = [\n",
    "    \"What is the capital of France?\",\n",
    "    \"How do I make pizza?\"\n",
    "]\n",
    "print(\"TODO: Test no-match questions\")\n",
    "for q in no_match_questions:\n",
    "    result = rag.query(q)\n",
    "    print(f\"\\nQ: {q}\")\n",
    "    print(f\"A: {result['answer'][:150]}...\")\n",
    "    print(f\"Distances (higher = less relevant): {result['distances']}\")\n",
    "\n",
    "# Ambiguous\n",
    "print(\"\\n--- AMBIGUOUS ---\")\n",
    "ambiguous_questions = [\n",
    "    \"Tell me about technology\",\n",
    "    \"What programming tools should I use?\"\n",
    "]\n",
    "print(\"TODO: Test ambiguous questions\")\n",
    "\n",
    "for q in ambiguous_questions:\n",
    "    result = rag.query(q)\n",
    "    print(f\"\\nQ: {q}\")\n",
    "    print(f\"A: {result['answer'][:150]}...\")\n",
    "    print(f\"Retrieved docs: {result['retrieved_docs']}\")\n",
    "    print(f\"Distances: {result['distances']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53e60faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Part 2: Edge Case Analysis\n",
      "============================================================\n",
      "\n",
      "--- 1. Empty/Short Queries ---\n",
      "\n",
      "Q: ''\n",
      "A: Based on the context: Machine learning enables systems to learn from experience without explicit pro...\n",
      "Distances: [1.728951096534729, 1.7767951488494873, 1.8401323556900024]\n",
      "\n",
      "Q: '?'\n",
      "A: Based on the context: Machine learning enables systems to learn from experience without explicit pro...\n",
      "Distances: [1.7679197788238525, 1.9057769775390625, 1.9309160709381104]\n",
      "\n",
      "Q: 'python'\n",
      "A: Based on the context: Python was created by Guido van Rossum and first released in 1991.\n",
      "Machine lea...\n",
      "Distances: [0.9062868356704712, 1.5207011699676514, 1.5896739959716797]\n",
      "\n",
      "--- 2. Very Long Query ---\n",
      "Q: I am trying to understand the historical development of programming languages \n",
      "a...\n",
      "A: Based on the context: Python was created by Guido van Rossum and first released in 1991.\n",
      "Git is a ve...\n",
      "Distances: [1.1133191585540771, 1.6809802055358887, 1.7537423372268677]\n",
      "\n",
      "--- 3. Typos ---\n",
      "\n",
      "Q: waht is mashcine lerning?\n",
      "A: Based on the context: REST is an architectural style using HTTP methods for networked applications.\n",
      "...\n",
      "Retrieved: REST is an architectural style using HTTP methods for networ...\n",
      "Distances: [1.643873691558838, 1.7576872110366821, 1.8426402807235718]\n",
      "\n",
      "Q: pytohn programming\n",
      "A: Based on the context: Neural networks are computing systems inspired by biological brains.\n",
      "Python wa...\n",
      "Retrieved: Neural networks are computing systems inspired by biological...\n",
      "Distances: [1.3572180271148682, 1.4058817625045776, 1.5025975704193115]\n",
      "\n",
      "--- 4. Opposite Meaning ---\n",
      "\n",
      "Q: What is NOT machine learning?\n",
      "A: Based on the context: Machine learning enables systems to learn from experience without explicit pro...\n",
      "Distances: [0.6649670600891113, 1.1797075271606445, 1.7085473537445068]\n",
      "\n",
      "Q: What did Git NOT do?\n",
      "A: Based on the context: Git is a version control system created by Linus Torvalds in 2005.\n",
      "Docker is a...\n",
      "Distances: [0.711110532283783, 1.6989003419876099, 1.9112184047698975]\n",
      "\n",
      "============================================================\n",
      "FAILURE MODE TABLE:\n",
      "============================================================\n",
      "\n",
      "| Failure Mode          | Example Query                  | What Happened                      | Possible Fix                    |\n",
      "|-----------------------|--------------------------------|------------------------------------|---------------------------------|\n",
      "| No relevant docs      | \"What is the capital of France?\"| Retrieved unrelated tech docs     | Add relevance threshold filter  |\n",
      "| Wrong docs retrieved  | \"waht is mashcine lerning?\"    | Typos may retrieve wrong docs     | Add spell-check preprocessing   |\n",
      "| Context too short     | \"python\"                       | Single word lacks context         | Require minimum query length    |\n",
      "| Context contradicts   | \"What is NOT machine learning?\"| Retrieved ML doc (ignores NOT)    | Use query rewriting/expansion   |\n",
      "| Empty query           | \"\"                             | May error or return random docs   | Validate input before query     |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# PART 2: Edge Case Analysis\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Part 2: Edge Case Analysis\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# TODO 2.1: Test edge cases\n",
    "print(\"\\n--- 1. Empty/Short Queries ---\")\n",
    "short_queries = [\"\", \"?\", \"python\"]\n",
    "for q in short_queries:\n",
    "    try:\n",
    "        result = rag.query(q)\n",
    "        print(f\"\\nQ: '{q}'\")\n",
    "        print(f\"A: {result['answer'][:100]}...\")\n",
    "        print(f\"Distances: {result['distances']}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nQ: '{q}' -> ERROR: {e}\")\n",
    "\n",
    "print(\"\\n--- 2. Very Long Query ---\")\n",
    "long_query = \"\"\"I am trying to understand the historical development of programming languages \n",
    "and how they have evolved over time, particularly focusing on interpreted languages that were \n",
    "designed for ease of use and readability, and I would also like to know about the creators \n",
    "of these languages and when they were first released to the public.\"\"\"\n",
    "result = rag.query(long_query)\n",
    "print(f\"Q: {long_query[:80]}...\")\n",
    "print(f\"A: {result['answer'][:100]}...\")\n",
    "print(f\"Distances: {result['distances']}\")\n",
    "\n",
    "print(\"\\n--- 3. Typos ---\")\n",
    "typo_queries = [\"waht is mashcine lerning?\", \"pytohn programming\"]\n",
    "for q in typo_queries:\n",
    "    result = rag.query(q)\n",
    "    print(f\"\\nQ: {q}\")\n",
    "    print(f\"A: {result['answer'][:100]}...\")\n",
    "    print(f\"Retrieved: {result['retrieved_docs'][0][:60]}...\")\n",
    "    print(f\"Distances: {result['distances']}\")\n",
    "\n",
    "print(\"\\n--- 4. Opposite Meaning ---\")\n",
    "opposite_queries = [\"What is NOT machine learning?\", \"What did Git NOT do?\"]\n",
    "for q in opposite_queries:\n",
    "    result = rag.query(q)\n",
    "    print(f\"\\nQ: {q}\")\n",
    "    print(f\"A: {result['answer'][:100]}...\")\n",
    "    print(f\"Distances: {result['distances']}\")\n",
    "\n",
    "# TODO 2.2: Failure Mode Identification\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FAILURE MODE TABLE:\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\"\"\n",
    "| Failure Mode          | Example Query                  | What Happened                           | Possible Fix                    |\n",
    "|-----------------------|--------------------------------|-----------------------------------------|---------------------------------|\n",
    "| No relevant docs      | \"What is the capital of France?\"| Distances ~1.9, returned unrelated docs | Add relevance threshold (>1.5)  |\n",
    "| Wrong docs retrieved  | \"waht is mashcine lerning?\"    | Got REST doc instead of ML (dist 1.64)  | Add spell-check preprocessing   |\n",
    "| Negation ignored      | \"What is NOT machine learning?\"| Retrieved ML doc anyway (dist 0.66!)    | Query rewriting or NLU layer    |\n",
    "| Empty query accepted  | \"\"                             | Returned random docs (dist ~1.73)       | Validate input before query     |\n",
    "| Typo misrouting       | \"pytohn programming\"           | Got Neural Networks first, not Python   | Fuzzy matching or autocorrect   |\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d71b4881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Part 3: Improvement Experiments\n",
      "============================================================\n",
      "\n",
      "--- K-VALUE EXPERIMENT ---\n",
      "\n",
      "k=1:\n",
      "  Docs retrieved: 1\n",
      "  Distances: [0.43]\n",
      "  Top doc: Python was created by Guido van Rossum and first r...\n",
      "\n",
      "k=3:\n",
      "  Docs retrieved: 3\n",
      "  Distances: [0.43, 1.64, 1.69]\n",
      "  Top doc: Python was created by Guido van Rossum and first r...\n",
      "\n",
      "k=5:\n",
      "  Docs retrieved: 5\n",
      "  Distances: [0.43, 1.64, 1.69, 1.69, 1.85]\n",
      "  Top doc: Python was created by Guido van Rossum and first r...\n",
      "\n",
      "k=6:\n",
      "  Docs retrieved: 6\n",
      "  Distances: [0.43, 1.64, 1.69, 1.69, 1.85, 1.97]\n",
      "  Top doc: Python was created by Guido van Rossum and first r...\n",
      "\n",
      "K-VALUE EXPERIMENT FINDINGS:\n",
      "| k value | Pros                          | Cons                           | Best For                    |\n",
      "|---------|-------------------------------|--------------------------------|-----------------------------|\n",
      "| k=1     | Fast, focused, less noise     | May miss relevant context      | Simple factual questions    |\n",
      "| k=3     | Good balance of context       | May include some irrelevant    | General purpose (default)   |\n",
      "| k=5     | More context for synthesis    | Higher chance of noise         | Complex multi-part questions|\n",
      "| k=6+    | Maximum context coverage      | Includes irrelevant docs       | When unsure what's relevant |\n",
      "\n",
      "\n",
      "--- THRESHOLD FILTERING ---\n",
      "\n",
      "Q: What year was Python released? (threshold=1.0)\n",
      "  Kept: 1 docs\n",
      "  Filtered out: 4 docs\n",
      "  Distances: [0.43]\n",
      "\n",
      "Q: What is the capital of France? (threshold=1.5)\n",
      "  Kept: 0 docs\n",
      "  Filtered out: 5 docs\n",
      "  Distances: []\n",
      "  -> Would return 'I don't have enough information'\n",
      "\n",
      "Threshold recommendations:\n",
      "  - threshold < 1.0: Very strict, only highly relevant\n",
      "  - threshold 1.0-1.5: Balanced filtering\n",
      "  - threshold > 1.5: Loose, allows marginal matches\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# PART 3: Improvement Experiments\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Part 3: Improvement Experiments\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ===================\n",
    "# TODO 3.1: Test different k values\n",
    "# ===================\n",
    "print(\"\\n--- K-VALUE EXPERIMENT ---\")\n",
    "test_question = \"What year was Python released?\"\n",
    "\n",
    "for k in [1, 3, 5, 6]:\n",
    "    result = rag.query(test_question, k=k)\n",
    "    print(f\"\\nk={k}:\")\n",
    "    print(f\"  Docs retrieved: {len(result['retrieved_docs'])}\")\n",
    "    print(f\"  Distances: {[round(d, 2) for d in result['distances']]}\")\n",
    "    print(f\"  Top doc: {result['retrieved_docs'][0][:50]}...\")\n",
    "\n",
    "print(\"\"\"\n",
    "K-VALUE EXPERIMENT FINDINGS:\n",
    "| k value | Pros                          | Cons                           | Best For                    |\n",
    "|---------|-------------------------------|--------------------------------|-----------------------------|\n",
    "| k=1     | Fast, focused, less noise     | May miss relevant context      | Simple factual questions    |\n",
    "| k=3     | Good balance of context       | May include some irrelevant    | General purpose (default)   |\n",
    "| k=5     | More context for synthesis    | Higher chance of noise         | Complex multi-part questions|\n",
    "| k=6+    | Maximum context coverage      | Includes irrelevant docs       | When unsure what's relevant |\n",
    "\"\"\")\n",
    "\n",
    "# ===================\n",
    "# TODO 3.2: Threshold filtering experiment\n",
    "# ===================\n",
    "print(\"\\n--- THRESHOLD FILTERING ---\")\n",
    "\n",
    "def query_with_threshold(rag, question, threshold=1.5):\n",
    "    \"\"\"Only use documents above relevance threshold.\"\"\"\n",
    "    result = rag.query(question, k=5)\n",
    "    \n",
    "    filtered_docs = []\n",
    "    filtered_distances = []\n",
    "    for doc, dist in zip(result['retrieved_docs'], result['distances']):\n",
    "        if dist < threshold:\n",
    "            filtered_docs.append(doc)\n",
    "            filtered_distances.append(dist)\n",
    "    \n",
    "    return {\n",
    "        \"question\": question,\n",
    "        \"answer\": result['answer'],\n",
    "        \"retrieved_docs\": filtered_docs,\n",
    "        \"distances\": filtered_distances,\n",
    "        \"filtered_out\": len(result['retrieved_docs']) - len(filtered_docs)\n",
    "    }\n",
    "\n",
    "# Test threshold on different queries\n",
    "test_queries = [\n",
    "    (\"What year was Python released?\", 1.0),\n",
    "    (\"What is the capital of France?\", 1.5),\n",
    "]\n",
    "\n",
    "for q, thresh in test_queries:\n",
    "    result = query_with_threshold(rag, q, threshold=thresh)\n",
    "    print(f\"\\nQ: {q} (threshold={thresh})\")\n",
    "    print(f\"  Kept: {len(result['retrieved_docs'])} docs\")\n",
    "    print(f\"  Filtered out: {result['filtered_out']} docs\")\n",
    "    print(f\"  Distances: {[round(d, 2) for d in result['distances']]}\")\n",
    "    if not result['retrieved_docs']:\n",
    "        print(\"  -> Would return 'I don't have enough information'\")\n",
    "\n",
    "print(\"\\nThreshold recommendations:\")\n",
    "print(\"  - threshold < 1.0: Very strict, only highly relevant\")\n",
    "print(\"  - threshold 1.0-1.5: Balanced filtering\")  \n",
    "print(\"  - threshold > 1.5: Loose, allows marginal matches\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703bcfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================\n",
    "# TODO 3.3: Document Change Experiments\n",
    "# ===================\n",
    "print(\"\\n--- DOCUMENT CHANGE EXPERIMENTS ---\")\n",
    "\n",
    "# Experiment 1: Add contradicting info\n",
    "print(\"\\n1. CONTRADICTING INFO:\")\n",
    "rag_conflict = SimpleRAG()\n",
    "rag_conflict.add_knowledge([\n",
    "    \"Python was created by Guido van Rossum and first released in 1991.\",\n",
    "    \"Python was created in 2020 by a team at Google.\",\n",
    "])\n",
    "result = rag_conflict.query(\"When was Python created?\")\n",
    "print(f\"Q: When was Python created?\")\n",
    "print(f\"Retrieved docs: {result['retrieved_docs']}\")\n",
    "print(f\"Distances: {[round(d, 2) for d in result['distances']]}\")\n",
    "print(\"-> RAG retrieves BOTH conflicting docs! LLM must handle contradiction.\")\n",
    "\n",
    "# Experiment 2: Add duplicate\n",
    "print(\"\\n2. DUPLICATE DOCUMENTS:\")\n",
    "rag_dup = SimpleRAG()\n",
    "rag_dup.add_knowledge([\n",
    "    \"Python was created by Guido van Rossum and first released in 1991.\",\n",
    "    \"Python was created by Guido van Rossum and first released in 1991.\",\n",
    "    \"Machine learning enables systems to learn from experience.\",\n",
    "], ids=[\"python1\", \"python2\", \"ml\"])\n",
    "result = rag_dup.query(\"What year was Python released?\", k=3)\n",
    "print(f\"Q: What year was Python released?\")\n",
    "print(f\"Retrieved docs: {result['retrieved_docs']}\")\n",
    "print(f\"Distances: {[round(d, 2) for d in result['distances']]}\")\n",
    "print(\"-> Duplicates waste retrieval slots with identical content.\")\n",
    "\n",
    "# Experiment 3: Missing document\n",
    "print(\"\\n3. MISSING DOCUMENT (no Python info):\")\n",
    "rag_missing = SimpleRAG()\n",
    "rag_missing.add_knowledge([\n",
    "    \"Machine learning enables systems to learn from experience.\",\n",
    "    \"Docker is a platform for running applications in containers.\",\n",
    "    \"Git is a version control system created by Linus Torvalds.\",\n",
    "])\n",
    "result = rag_missing.query(\"What year was Python released?\")\n",
    "print(f\"Q: What year was Python released?\")\n",
    "print(f\"Retrieved docs: {result['retrieved_docs']}\")\n",
    "print(f\"Distances: {[round(d, 2) for d in result['distances']]}\")\n",
    "print(\"-> Still returns docs! High distances indicate no good match.\")\n",
    "\n",
    "print(\"\"\"\n",
    "DOCUMENT CHANGE FINDINGS:\n",
    "| Scenario              | Observation                           | Mitigation                      |\n",
    "|-----------------------|---------------------------------------|---------------------------------|\n",
    "| Contradicting docs    | Both retrieved, LLM sees conflict     | Dedup or version control docs   |\n",
    "| Duplicate docs        | Wastes k slots with same content      | Deduplicate before indexing     |\n",
    "| Missing relevant doc  | Returns unrelated docs (high dist)    | Use distance threshold filter   |\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9de97d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PART 4: Written Analysis\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Part 4: Written Analysis\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\"\"\n",
    "RAG STRENGTHS:\n",
    "(What problems does RAG solve well?)\n",
    "- Grounds LLM responses in actual data (reduces hallucination)\n",
    "- Works well for direct factual questions\n",
    "- No retraining needed - just update the document store\n",
    "\n",
    "RAG LIMITATIONS:\n",
    "- Always returns docs even when no relevant info exists(with out current implementation)\n",
    "- Ignores negation (\"NOT machine learning\" still retrieves ML)\n",
    "- Typos break retrieval\n",
    "- Can't synthesize well across multiple unrelated docs\n",
    "\n",
    "PRODUCTION CONSIDERATIONS:\n",
    "- Add distance threshold (~1.5) to reject low-quality matches\n",
    "- Validate/preprocess queries \n",
    "- Deduplicate documents before indexing\n",
    "- Choose k based on use case (k=1 for facts, k=3+ for context)\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Exercise Complete!\")\n",
    "print(\"=\" * 60)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
