{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b54a1cd9",
   "metadata": {},
   "source": [
    "\n",
    "# Personal Reflection\n",
    "\n",
    "The original code provided a use case that was too easy so the mask vs unmassked was unidentifiable. So a longer sequence was created so that the unmasked imolementation would fail(be less accurate.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e11e1f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-padded:\n",
      "[[ 0  0  0  1  2  3]\n",
      " [ 0  4  5  6  7  8]\n",
      " [ 0  0  0  0  9 10]]\n",
      "\n",
      "Post-padded:\n",
      "[[ 1  2  3  0  0  0]\n",
      " [ 4  5  6  7  8  0]\n",
      " [ 9 10  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "sequences = [\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6, 7, 8],\n",
    "    [9, 10]\n",
    "]\n",
    "\n",
    "pre_padded = pad_sequences(sequences, maxlen=6, padding='pre')\n",
    "print(\"Pre-padded:\")\n",
    "print(pre_padded)\n",
    "\n",
    "post_padded = pad_sequences(sequences, maxlen=6, padding='post')\n",
    "print(\"\\nPost-padded:\")\n",
    "print(post_padded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201b77fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sequence: [1, 2, 3]\n",
      "Pre-padded:  [0 0 0 1 2 3] -> RNN processes: [0,0,0] then [1,2,3] -> final state from CONTENT\n",
      "Post-padded: [1 2 3 0 0 0] -> RNN processes: [1,2,3] then [0,0,0] -> final state from PADDING\n",
      "\n",
      "--- Visual Timeline ---\n",
      "Pre-padding:  [pad][pad][pad][1][2][3] -> Final state = f(3)\n",
      "Post-padding: [1][2][3][pad][pad][pad] -> Final state = f(0)\n",
      "\n",
      "--- Hidden States at Each Timestep ---\n",
      "Pre-padded sequence hidden states:\n",
      "  t=0 (input=0): [0. 0. 0. 0.]\n",
      "  t=1 (input=0): [0. 0. 0. 0.]\n",
      "  t=2 (input=0): [0. 0. 0. 0.]\n",
      "  t=3 (input=1): [ 0.524 -0.438  0.516 -0.73 ]\n",
      "  t=4 (input=2): [ 0.812 -0.957  0.532 -0.964]\n",
      "  t=5 (input=3): [ 0.947 -0.993  0.673 -0.989]\n",
      "\n",
      "Post-padded sequence hidden states:\n",
      "  t=0 (input=1): [ 0.524 -0.438  0.516 -0.73 ]\n",
      "  t=1 (input=2): [ 0.812 -0.957  0.532 -0.964]\n",
      "  t=2 (input=3): [ 0.947 -0.993  0.673 -0.989]\n",
      "  t=3 (input=0): [-0.023 -0.902 -0.782  0.12 ]\n",
      "  t=4 (input=0): [ 0.431 -0.02  -0.073  0.802]\n",
      "  t=5 (input=0): [-0.21   0.59  -0.488  0.209]\n",
      "\n",
      "Final state (pre):  [[ 0.947 -0.993  0.673 -0.989]] <- Captures actual content!\n",
      "Final state (post): [[-0.21   0.59  -0.488  0.209]] <- Contaminated by padding!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def explain_padding_difference():\n",
    "    \"\"\"\n",
    "    Explain why pre-padding is better for classification.\n",
    "    \n",
    "    With pre-padding:\n",
    "    - Actual content is at the END of the sequence\n",
    "    - RNN's final hidden state captures actual content\n",
    "    - Final state is used for classification\n",
    "    \n",
    "    With post-padding:\n",
    "    - Actual content is at the BEGINNING\n",
    "    - RNN processes padding AFTER content\n",
    "    - Final state is influenced by padding zeros\n",
    "    \"\"\"\n",
    "    seq = [[1, 2, 3]]\n",
    "    \n",
    "    pre = pad_sequences(seq, maxlen=6, padding='pre')\n",
    "    post = pad_sequences(seq, maxlen=6, padding='post')\n",
    "    \n",
    "    print(\"Original sequence: [1, 2, 3]\")\n",
    "    print(f\"Pre-padded:  {pre[0]} -> RNN processes: [0,0,0] then [1,2,3] -> final state from CONTENT\")\n",
    "    print(f\"Post-padded: {post[0]} -> RNN processes: [1,2,3] then [0,0,0] -> final state from PADDING\")\n",
    "    \n",
    "    print(\"\\n--- Visual Timeline ---\")\n",
    "    print(\"Pre-padding:  [pad][pad][pad][1][2][3] -> Final state = f(3)\")\n",
    "    print(\"Post-padding: [1][2][3][pad][pad][pad] -> Final state = f(0)\")\n",
    "    \n",
    "    # Build simple models to show hidden state difference\n",
    "    rnn = layers.SimpleRNN(4, return_sequences=True, return_state=True)\n",
    "    \n",
    "    pre_seq, post_seq = np.array(pre, dtype=np.float32), np.array(post, dtype=np.float32)\n",
    "    pre_seq = pre_seq.reshape(1, 6, 1)\n",
    "    post_seq = post_seq.reshape(1, 6, 1)\n",
    "    \n",
    "    pre_out, pre_state = rnn(pre_seq)\n",
    "    post_out, post_state = rnn(post_seq)\n",
    "    \n",
    "    print(\"\\n--- Hidden States at Each Timestep ---\")\n",
    "    print(\"Pre-padded sequence hidden states:\")\n",
    "    for i, h in enumerate(pre_out[0].numpy()):\n",
    "        print(f\"  t={i} (input={pre[0][i]}): {h.round(3)}\")\n",
    "    \n",
    "    print(\"\\nPost-padded sequence hidden states:\")\n",
    "    for i, h in enumerate(post_out[0].numpy()):\n",
    "        print(f\"  t={i} (input={post[0][i]}): {h.round(3)}\")\n",
    "    \n",
    "    print(f\"\\nFinal state (pre):  {pre_state.numpy().round(3)} <- Captures actual content!\")\n",
    "    print(f\"Final state (post): {post_state.numpy().round(3)} <- Contaminated by padding!\")\n",
    "\n",
    "explain_padding_difference()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77ed933",
   "metadata": {},
   "source": [
    "### Task 1.2: Truncation Strategies\n",
    "When sequences exceed max_length, you must truncate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "92b2acd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-truncated (keep end):\n",
      "[[ 6  7  8  9 10]\n",
      " [11 12 13 14 15]]\n",
      "-> Removes from beginning, keeps last 5 elements\n",
      "\n",
      "Post-truncated (keep beginning):\n",
      "[[ 1  2  3  4  5]\n",
      " [11 12 13 14 15]]\n",
      "-> Removes from end, keeps first 5 elements\n",
      "\n",
      "--- When to use each ---\n",
      "Pre-truncating (keep END): Good for sentiment where final words matter most\n",
      "Post-truncating (keep BEGIN): Good for documents where intro is key\n"
     ]
    }
   ],
   "source": [
    "long_sequences = [\n",
    "    [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    [11, 12, 13, 14, 15]\n",
    "]\n",
    "\n",
    "pre_truncated = pad_sequences(long_sequences, maxlen=5, truncating='pre')\n",
    "print(\"Pre-truncated (keep end):\")\n",
    "print(pre_truncated)\n",
    "print(\"-> Removes from beginning, keeps last 5 elements\")\n",
    "\n",
    "post_truncated = pad_sequences(long_sequences, maxlen=5, truncating='post')\n",
    "print(\"\\nPost-truncated (keep beginning):\")\n",
    "print(post_truncated)\n",
    "print(\"-> Removes from end, keeps first 5 elements\")\n",
    "\n",
    "print(\"\\n--- When to use each ---\")\n",
    "print(\"Pre-truncating (keep END): Good for sentiment where final words matter most\")\n",
    "print(\"Post-truncating (keep BEGIN): Good for documents where intro is key\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5318c109",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bddf96",
   "metadata": {},
   "source": [
    "## Part 3: Complete Pipeline Class\n",
    "### Task 3.1: Build Production Pipeline\n",
    "Create a reusable preprocessing class that handles tokenization, vocabulary building, padding, and train/test consistency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c5e2584d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequencePreprocessor class defined!\n"
     ]
    }
   ],
   "source": [
    "class SequencePreprocessor:\n",
    "    \"\"\"\n",
    "    Complete preprocessing pipeline for sequence data.\n",
    "    \n",
    "    Handles:\n",
    "    - Tokenization\n",
    "    - Vocabulary building with size limits\n",
    "    - Padding and truncation\n",
    "    - Train/test consistency\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, max_vocab_size=10000, max_length=None, \n",
    "                 padding='pre', truncating='pre'):\n",
    "        self.max_vocab_size = max_vocab_size\n",
    "        self.max_length = max_length\n",
    "        self.padding = padding\n",
    "        self.truncating = truncating\n",
    "        self.tokenizer = None\n",
    "        self.fitted = False\n",
    "    \n",
    "    def fit(self, texts):\n",
    "        \"\"\"Fit tokenizer on training texts.\"\"\"\n",
    "        from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "        \n",
    "        self.tokenizer = Tokenizer(\n",
    "            num_words=self.max_vocab_size,\n",
    "            oov_token='<UNK>'\n",
    "        )\n",
    "        self.tokenizer.fit_on_texts(texts)\n",
    "        \n",
    "        # If max_length not set, use 95th percentile\n",
    "        if self.max_length is None:\n",
    "            sequences = self.tokenizer.texts_to_sequences(texts)\n",
    "            lengths = [len(s) for s in sequences]\n",
    "            self.max_length = int(np.percentile(lengths, 95))\n",
    "        \n",
    "        self.fitted = True\n",
    "        return self\n",
    "    \n",
    "    def transform(self, texts):\n",
    "        \"\"\"Transform texts to padded sequences.\"\"\"\n",
    "        if not self.fitted:\n",
    "            raise ValueError(\"Preprocessor not fitted. Call fit() first.\")\n",
    "        \n",
    "        sequences = self.tokenizer.texts_to_sequences(texts)\n",
    "        padded = pad_sequences(\n",
    "            sequences,\n",
    "            maxlen=self.max_length,\n",
    "            padding=self.padding,\n",
    "            truncating=self.truncating\n",
    "        )\n",
    "        return padded\n",
    "    \n",
    "    def fit_transform(self, texts):\n",
    "        \"\"\"Fit and transform in one step.\"\"\"\n",
    "        return self.fit(texts).transform(texts)\n",
    "    \n",
    "    @property\n",
    "    def vocab_size(self):\n",
    "        \"\"\"Return vocabulary size.\"\"\"\n",
    "        if self.tokenizer is None:\n",
    "            return 0\n",
    "        return min(len(self.tokenizer.word_index) + 1, self.max_vocab_size)\n",
    "    \n",
    "    def get_config(self):\n",
    "        \"\"\"Return configuration for model building.\"\"\"\n",
    "        return {\n",
    "            'vocab_size': self.vocab_size,\n",
    "            'max_length': self.max_length,\n",
    "            'embedding_dim': 128\n",
    "        }\n",
    "\n",
    "print(\"SequencePreprocessor class defined!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b021859",
   "metadata": {},
   "source": [
    "### Task 3.2: Test Complete Pipeline\n",
    "Use the preprocessor on sample movie reviews and build a model from the config.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "18964aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: {'vocab_size': 54, 'max_length': 7, 'embedding_dim': 128}\n",
      "Processed shape: (10, 7)\n",
      "\n",
      "First review: 'This movie was absolutely fantastic! Great acting.'\n",
      "Tokenized & padded: [ 6  4  7  8  9 10 11]\n"
     ]
    }
   ],
   "source": [
    "# Sample movie reviews\n",
    "train_texts = [\n",
    "    \"This movie was absolutely fantastic! Great acting.\",\n",
    "    \"Terrible film. Complete waste of time.\",\n",
    "    \"An average movie, nothing special.\",\n",
    "    \"One of the best I've seen in years!\",\n",
    "    \"Boring and predictable storyline.\",\n",
    "    \"A masterpiece of modern cinema.\",\n",
    "    \"Couldn't finish it, too slow and dull.\",\n",
    "    \"Incredible performances by the entire cast.\",\n",
    "    \"Generic plot with no surprises.\",\n",
    "    \"Visually stunning and emotionally powerful.\"\n",
    "]\n",
    "\n",
    "train_labels = np.array([1, 0, 0, 1, 0, 1, 0, 1, 0, 1])\n",
    "\n",
    "# Test pipeline\n",
    "preprocessor = SequencePreprocessor(max_vocab_size=1000)\n",
    "X_train = preprocessor.fit_transform(train_texts)\n",
    "\n",
    "print(f\"Config: {preprocessor.get_config()}\")\n",
    "print(f\"Processed shape: {X_train.shape}\")\n",
    "print(f\"\\nFirst review: '{train_texts[0]}'\")\n",
    "print(f\"Tokenized & padded: {X_train[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "26198686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_10\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_10\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_10 (\u001b[38;5;33mEmbedding\u001b[0m)        │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_10 (\u001b[38;5;33mLSTM\u001b[0m)                  │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training on sample data...\n",
      "Training accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Build model using config from preprocessor\n",
    "config = preprocessor.get_config()\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Embedding(config['vocab_size'], config['embedding_dim'], \n",
    "                     input_length=config['max_length'], mask_zero=True),\n",
    "    layers.LSTM(64),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Quick training demo\n",
    "print(\"\\nTraining on sample data...\")\n",
    "model.fit(X_train, train_labels, epochs=10, verbose=0)\n",
    "print(f\"Training accuracy: {model.evaluate(X_train, train_labels, verbose=0)[1]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bad3d354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform on new test data:\n",
      "Test shape: (3, 7)\n",
      "\n",
      "Predictions on test data:\n",
      "  'Amazing film, highly recommend!...' -> Positive (0.51)\n",
      "  'Worst movie ever made....' -> Positive (0.51)\n",
      "  'Great special effects but weak story....' -> Positive (0.53)\n"
     ]
    }
   ],
   "source": [
    "# Test transform on NEW data (simulating test set)\n",
    "test_texts = [\n",
    "    \"Amazing film, highly recommend!\",\n",
    "    \"Worst movie ever made.\",\n",
    "    \"Great special effects but weak story.\"\n",
    "]\n",
    "\n",
    "X_test = preprocessor.transform(test_texts)  # Uses SAME tokenizer/config as training\n",
    "print(\"Transform on new test data:\")\n",
    "print(f\"Test shape: {X_test.shape}\")\n",
    "print(f\"\\nPredictions on test data:\")\n",
    "for text, pred in zip(test_texts, model.predict(X_test, verbose=0)):\n",
    "    sentiment = \"Positive\" if pred > 0.5 else \"Negative\"\n",
    "    print(f\"  '{text[:40]}...' -> {sentiment} ({pred[0]:.2f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbfafe2",
   "metadata": {},
   "source": [
    "## Reflection Questions\n",
    "\n",
    "**1. Why is pre-padding preferred for classification?**\n",
    "\n",
    "The LSTM's final  state comes from the last step - with pre-padding that's actual content, with post-padding it's zeros.\n",
    "\n",
    "**2. When would post-padding be better?**\n",
    "\n",
    "tasks where you need the decoder to start from the actual beginning of the sequence.\n",
    "\n",
    "**3. What happens if you don't use masking with heavily padded data?**\n",
    "\n",
    "Model still learns but wastes capacity processing zeros and performance might drops if the padding ratio is high.\n",
    "\n",
    "**4. How would you handle a dataset where 5% of sequences are 10x longer than average?**\n",
    "\n",
    "Truncate to ~95th percentile length because the logner seqences are probably exceptions and liely not a greate reperestation of the rest of the data(given that they are outliers) \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
