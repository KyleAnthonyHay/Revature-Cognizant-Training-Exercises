{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dc0e6a6",
   "metadata": {},
   "source": [
    "# Embeddings\n",
    "\n",
    "representing words as vectors\n",
    "\n",
    "Tokenization -> Embeddings -> Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52dffe43",
   "metadata": {},
   "source": [
    "## Old Solution: One-hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf5063f",
   "metadata": {},
   "source": [
    "\n",
    "Vocabulary: [\"I\", \"love\", \"NLP\", \"deep\", \"learning\"] (5 words)\n",
    "\n",
    "\"love\" → [0, 1, 0, 0, 0]  ← 5 dimensions, only one \"1\"\n",
    "\"NLP\"  → [0, 0, 1, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dba8353",
   "metadata": {},
   "source": [
    "### Issues\n",
    "\n",
    "It's Inefficeint as vocabulary grows:\n",
    "\n",
    "if vocab size = 16 <br>\n",
    "\n",
    "```[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,] = \"love\"```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7a3afe",
   "metadata": {},
   "source": [
    "## Better Solution: Embedding layer\n",
    "\n",
    "### Input: [45, 123, 7, 891] (4 word indices)\n",
    "### Output: (4, 10) matrix — 4 dense 10-dimensional vectors\n",
    "\n",
    "if vocab was 1,000, the vector length is only 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29cf14b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 10)\n"
     ]
    }
   ],
   "source": [
    "#  Example of pretrained weights\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "pretrained_embeddings = np.array([\n",
    "    # word index 0\n",
    "    [ 0.12, -0.45,  0.33,  0.91, -0.22,  0.05,  0.67, -0.14,  0.28,  0.40],\n",
    "    \n",
    "    # word index 1\n",
    "    [-0.30,  0.88, -0.12,  0.44,  0.09, -0.55,  0.31,  0.72, -0.08,  0.15],\n",
    "    \n",
    "    # word index 2\n",
    "    [ 0.95,  0.10, -0.66, -0.21,  0.48,  0.77, -0.34,  0.02,  0.59, -0.90],\n",
    "    \n",
    "    # word index 3\n",
    "    [-0.11, -0.22,  0.13,  0.64,  0.51, -0.07,  0.84,  0.29, -0.41,  0.06]\n",
    "])\n",
    "\n",
    "print(pretrained_embeddings.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
