{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "2bf11c35",
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Exercise 01: Dynamic Prompts - Starter Code\n",
        "===========================================\n",
        "Build an agent with context-aware system prompts.\n",
        "\n",
        "LEARNING GOALS:\n",
        "- Import and use @dynamic_prompt decorator\n",
        "- Read from ModelRequest to access state\n",
        "- Build adaptive prompts based on context\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "from datetime import datetime\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "from langchain.agents import create_agent\n",
        "from langchain.chat_models import init_chat_model\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "model = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# TODO 1: Import Dynamic Prompt Components\n",
        "# =============================================================================\n",
        "# Import from langchain.agents.middleware:\n",
        "# - dynamic_prompt (decorator)\n",
        "# - ModelRequest (type for the request object)\n",
        "# =============================================================================\n",
        "\n",
        "from langchain.agents.middleware import dynamic_prompt, ModelRequest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "23e5d398",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# =============================================================================\n",
        "# TODO 2: Create Tools\n",
        "# =============================================================================\n",
        "\n",
        "@tool\n",
        "def explain_concept(topic: str) -> str:\n",
        "    \"\"\"Explain a programming concept.\"\"\"\n",
        "    response = model.invoke(f\"Explain the programming concept: {topic}. Be clear and concise.\")\n",
        "    return response.content\n",
        "\n",
        "\n",
        "@tool\n",
        "def write_code(description: str) -> str:\n",
        "    \"\"\"Write code for a given task description.\"\"\"\n",
        "    response = model.invoke(f\"Write code for: {description}. Provide complete, working code.\")\n",
        "    return response.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "38704c0d",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# =============================================================================\n",
        "# TODO 3: Implement Dynamic Prompt Middleware\n",
        "# =============================================================================\n",
        "# Create a function decorated with @dynamic_prompt that:\n",
        "# 1. Receives a ModelRequest parameter\n",
        "# 2. Reads experience_level from request.state (default: \"intermediate\")\n",
        "# 3. Gets time of day from datetime.now().hour\n",
        "# 4. Checks conversation length via len(request.messages)\n",
        "# 5. Returns a customized system prompt string\n",
        "#\n",
        "# Adaptations to implement:\n",
        "# - Beginner: simple language, analogies, step-by-step\n",
        "# - Intermediate: balanced explanations with code\n",
        "# - Expert: concise, technical terms freely\n",
        "# - Morning: cheerful greeting\n",
        "# - Long conversations: more concise responses\n",
        "#\n",
        "# EXPERIMENT: Add language preference adaptation\n",
        "# EXPERIMENT: Add domain-specific adaptations (web dev vs data science)\n",
        "# =============================================================================\n",
        "\n",
        "@dynamic_prompt\n",
        "def adaptive_prompt(request: ModelRequest) -> str:\n",
        "    experience = request.state.get(\"experience_level\", \"intermediate\")\n",
        "    hour = datetime.now().hour\n",
        "    message_count = len(request.messages)\n",
        "    \n",
        "    greeting = \"\"\n",
        "    if 5 <= hour < 12:\n",
        "        greeting = \"Good morning! \"\n",
        "    \n",
        "    experience_style = \"\"\n",
        "    if experience == \"beginner\":\n",
        "        experience_style = \"Use simple language, analogies, and step-by-step explanations. Avoid jargon unless you explain it first.\"\n",
        "    elif experience == \"expert\":\n",
        "        experience_style = \"Be concise and use technical terms freely. Assume deep knowledge.\"\n",
        "    else:\n",
        "        experience_style = \"Provide balanced explanations with code examples. Use technical terms but explain when helpful.\"\n",
        "    \n",
        "    conciseness = \"\"\n",
        "    if message_count > 10:\n",
        "        conciseness = \" Keep responses concise as this is a longer conversation.\"\n",
        "    \n",
        "    prompt = f\"{greeting}You are a helpful programming assistant. {experience_style}{conciseness}\"\n",
        "    return prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "250e44fa",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# =============================================================================\n",
        "# TODO 4: Create the Agent\n",
        "# =============================================================================\n",
        "# Create an agent that:\n",
        "# - Uses your tools\n",
        "# - Uses your adaptive_prompt middleware\n",
        "# - Does NOT include checkpointer (for Studio export)\n",
        "# =============================================================================\n",
        "\n",
        "agent = create_agent(\n",
        "    model=model,\n",
        "    tools=[explain_concept, write_code],\n",
        "    middleware=[adaptive_prompt],\n",
        "    name=\"adaptive_programming_agent\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "893c9d34",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test with different experience levels:\n",
            "- Set 'experience_level': 'beginner' in state\n",
            "- Set 'experience_level': 'expert' in state\n",
            "- Ask the same question and compare responses!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# =============================================================================\n",
        "# CLI Testing\n",
        "# =============================================================================\n",
        "from langgraph.checkpoint.memory import InMemorySaver\n",
        "\n",
        "checkpointer = InMemorySaver()\n",
        "\n",
        "cli_agent = create_agent(\n",
        "    model=model,\n",
        "    tools=[explain_concept, write_code],\n",
        "    middleware=[adaptive_prompt],\n",
        "    checkpointer=checkpointer,\n",
        "    name=\"adaptive_programming_agent_cli\"\n",
        ")\n",
        "\n",
        "def test_agent(experience_level: str, question: str):\n",
        "    config = {\n",
        "        \"configurable\": {\n",
        "            \"thread_id\": f\"test_{experience_level}\",\n",
        "            \"state\": {\"experience_level\": experience_level}\n",
        "        }\n",
        "    }\n",
        "    \n",
        "    result = cli_agent.invoke(\n",
        "        {\"messages\": [{\"role\": \"user\", \"content\": question}]},\n",
        "        config\n",
        "    )\n",
        "    \n",
        "    return result[\"messages\"][-1].content\n",
        "\n",
        "print(\"Testing with different experience levels:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "question = \"What is a decorator in Python?\"\n",
        "\n",
        "print(f\"\\nQuestion: {question}\\n\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "print(\"\\nBEGINNER response:\")\n",
        "print(\"-\" * 60)\n",
        "beginner_response = test_agent(\"beginner\", question)\n",
        "print(beginner_response)\n",
        "\n",
        "print(\"\\n\\nEXPERT response:\")\n",
        "print(\"-\" * 60)\n",
        "expert_response = test_agent(\"expert\", question)\n",
        "print(expert_response)\n",
        "\n",
        "print(\"\\n\\nINTERMEDIATE response:\")\n",
        "print(\"-\" * 60)\n",
        "intermediate_response = test_agent(\"intermediate\", question)\n",
        "print(intermediate_response)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
