{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# RAG Application with AWS Bedrock & ChromaDB (Cloud)\n",
                "## Phase 1: Setup & Configuration\n",
                "This notebook covers the setup of dependencies, configuration of credentials, and initialization of AWS Bedrock and ChromaDB Cloud clients."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Requirement already satisfied: boto3 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (1.42.23)\n",
                        "Requirement already satisfied: chromadb in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (1.4.0)\n",
                        "Requirement already satisfied: langchain in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (1.2.1)\n",
                        "Requirement already satisfied: langchain-community in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (0.4.1)\n",
                        "Requirement already satisfied: langchain-aws in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (1.2.0)\n",
                        "Requirement already satisfied: langchain-text-splitters in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (1.1.0)\n",
                        "Requirement already satisfied: python-dotenv in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (1.2.1)\n",
                        "Requirement already satisfied: botocore<1.43.0,>=1.42.23 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from boto3) (1.42.23)\n",
                        "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from boto3) (1.0.1)\n",
                        "Requirement already satisfied: s3transfer<0.17.0,>=0.16.0 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from boto3) (0.16.0)\n",
                        "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from botocore<1.43.0,>=1.42.23->boto3) (2.9.0.post0)\n",
                        "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from botocore<1.43.0,>=1.42.23->boto3) (2.3.0)\n",
                        "Requirement already satisfied: six>=1.5 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.43.0,>=1.42.23->boto3) (1.17.0)\n",
                        "Requirement already satisfied: build>=1.0.3 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from chromadb) (1.3.0)\n",
                        "Requirement already satisfied: pydantic>=1.9 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from chromadb) (2.12.5)\n",
                        "Requirement already satisfied: pybase64>=1.4.1 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from chromadb) (1.4.3)\n",
                        "Requirement already satisfied: uvicorn>=0.18.3 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.40.0)\n",
                        "Requirement already satisfied: numpy>=1.22.5 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from chromadb) (2.4.0)\n",
                        "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from chromadb) (5.4.0)\n",
                        "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from chromadb) (4.15.0)\n",
                        "Requirement already satisfied: onnxruntime>=1.14.1 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from chromadb) (1.23.2)\n",
                        "Requirement already satisfied: opentelemetry-api>=1.2.0 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from chromadb) (1.39.1)\n",
                        "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from chromadb) (1.39.1)\n",
                        "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from chromadb) (1.39.1)\n",
                        "Requirement already satisfied: tokenizers>=0.13.2 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from chromadb) (0.22.1)\n",
                        "Requirement already satisfied: pypika>=0.48.9 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from chromadb) (0.48.9)\n",
                        "Requirement already satisfied: tqdm>=4.65.0 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from chromadb) (4.67.1)\n",
                        "Requirement already satisfied: overrides>=7.3.1 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from chromadb) (7.7.0)\n",
                        "Requirement already satisfied: importlib-resources in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from chromadb) (6.5.2)\n",
                        "Requirement already satisfied: grpcio>=1.58.0 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from chromadb) (1.76.0)\n",
                        "Requirement already satisfied: bcrypt>=4.0.1 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from chromadb) (5.0.0)\n",
                        "Requirement already satisfied: typer>=0.9.0 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from chromadb) (0.21.0)\n",
                        "Requirement already satisfied: kubernetes>=28.1.0 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from chromadb) (34.1.0)\n",
                        "Requirement already satisfied: tenacity>=8.2.3 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from chromadb) (9.1.2)\n",
                        "Requirement already satisfied: pyyaml>=6.0.0 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from chromadb) (6.0.3)\n",
                        "Requirement already satisfied: mmh3>=4.0.1 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from chromadb) (5.2.0)\n",
                        "Requirement already satisfied: orjson>=3.9.12 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from chromadb) (3.11.5)\n",
                        "Requirement already satisfied: httpx>=0.27.0 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from chromadb) (0.28.1)\n",
                        "Requirement already satisfied: rich>=10.11.0 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from chromadb) (14.2.0)\n",
                        "Requirement already satisfied: jsonschema>=4.19.0 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from chromadb) (4.25.1)\n",
                        "Requirement already satisfied: requests<3.0,>=2.7 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.32.5)\n",
                        "Requirement already satisfied: backoff>=1.10.0 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.2.1)\n",
                        "Requirement already satisfied: distro>=1.5.0 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
                        "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb) (3.4.4)\n",
                        "Requirement already satisfied: idna<4,>=2.5 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb) (3.11)\n",
                        "Requirement already satisfied: certifi>=2017.4.17 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb) (2025.11.12)\n",
                        "Requirement already satisfied: langchain-core<2.0.0,>=1.2.1 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from langchain) (1.2.6)\n",
                        "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from langchain) (1.0.5)\n",
                        "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (1.33)\n",
                        "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (0.6.1)\n",
                        "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (25.0)\n",
                        "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (0.12.0)\n",
                        "Requirement already satisfied: jsonpointer>=1.9 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.1->langchain) (3.0.0)\n",
                        "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.1)\n",
                        "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.5)\n",
                        "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.3.1)\n",
                        "Requirement already satisfied: xxhash>=3.5.0 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
                        "Requirement already satisfied: ormsgpack>=1.12.0 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.1)\n",
                        "Requirement already satisfied: requests-toolbelt>=1.0.0 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (1.0.0)\n",
                        "Requirement already satisfied: zstandard>=0.23.0 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (0.25.0)\n",
                        "Requirement already satisfied: anyio in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb) (4.12.0)\n",
                        "Requirement already satisfied: httpcore==1.* in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
                        "Requirement already satisfied: h11>=0.16 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
                        "Requirement already satisfied: annotated-types>=0.6.0 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
                        "Requirement already satisfied: pydantic-core==2.41.5 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from pydantic>=1.9->chromadb) (2.41.5)\n",
                        "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from pydantic>=1.9->chromadb) (0.4.2)\n",
                        "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from langchain-community) (1.0.1)\n",
                        "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from langchain-community) (2.0.45)\n",
                        "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from langchain-community) (3.13.3)\n",
                        "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from langchain-community) (0.6.7)\n",
                        "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from langchain-community) (2.12.0)\n",
                        "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from langchain-community) (0.4.3)\n",
                        "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
                        "Requirement already satisfied: aiosignal>=1.4.0 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
                        "Requirement already satisfied: attrs>=17.3.0 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
                        "Requirement already satisfied: frozenlist>=1.1.1 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
                        "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
                        "Requirement already satisfied: propcache>=0.2.0 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
                        "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
                        "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.2)\n",
                        "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
                        "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n",
                        "Requirement already satisfied: pyproject_hooks in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
                        "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\n",
                        "Requirement already satisfied: referencing>=0.28.4 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from jsonschema>=4.19.0->chromadb) (0.37.0)\n",
                        "Requirement already satisfied: rpds-py>=0.7.1 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from jsonschema>=4.19.0->chromadb) (0.30.0)\n",
                        "Requirement already satisfied: google-auth>=1.0.1 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (2.45.0)\n",
                        "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (1.9.0)\n",
                        "Requirement already satisfied: requests-oauthlib in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
                        "Requirement already satisfied: durationpy>=0.7 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (0.10)\n",
                        "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (6.2.4)\n",
                        "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
                        "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
                        "Requirement already satisfied: pyasn1>=0.1.3 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from rsa<5,>=3.1.4->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
                        "Requirement already satisfied: coloredlogs in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
                        "Requirement already satisfied: flatbuffers in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb) (25.12.19)\n",
                        "Requirement already satisfied: protobuf in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb) (6.33.2)\n",
                        "Requirement already satisfied: sympy in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\n",
                        "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.1)\n",
                        "Requirement already satisfied: zipp>=3.20 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
                        "Requirement already satisfied: googleapis-common-protos~=1.57 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.72.0)\n",
                        "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.39.1 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.39.1)\n",
                        "Requirement already satisfied: opentelemetry-proto==1.39.1 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.39.1)\n",
                        "Requirement already satisfied: opentelemetry-semantic-conventions==0.60b1 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.60b1)\n",
                        "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
                        "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
                        "Requirement already satisfied: mdurl~=0.1 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
                        "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from tokenizers>=0.13.2->chromadb) (0.36.0)\n",
                        "Requirement already satisfied: filelock in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.20.1)\n",
                        "Requirement already satisfied: fsspec>=2023.5.0 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.12.0)\n",
                        "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (1.2.0)\n",
                        "Requirement already satisfied: click>=8.0.0 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from typer>=0.9.0->chromadb) (8.3.1)\n",
                        "Requirement already satisfied: shellingham>=1.3.0 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
                        "Requirement already satisfied: httptools>=0.6.3 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.7.1)\n",
                        "Requirement already satisfied: uvloop>=0.15.1 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.22.1)\n",
                        "Requirement already satisfied: watchfiles>=0.13 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n",
                        "Requirement already satisfied: websockets>=10.4 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
                        "Requirement already satisfied: humanfriendly>=9.1 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
                        "Requirement already satisfied: oauthlib>=3.0.0 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb) (3.3.1)\n",
                        "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
                        "Note: you may need to restart the kernel to use updated packages.\n"
                    ]
                }
            ],
            "source": [
                "# Step 1: Install Dependencies\n",
                "# Using %pip ensures packages are installed in the current Jupyter kernel\n",
                "%pip install boto3 chromadb langchain langchain-community langchain-aws langchain-text-splitters python-dotenv"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Configuration Loaded.\n"
                    ]
                }
            ],
            "source": [
                "# Step 2: Configuration & Variables\n",
                "import os\n",
                "from dotenv import load_dotenv\n",
                "import chromadb\n",
                "from chromadb.config import Settings\n",
                "\n",
                "# Load environment variables from .env file\n",
                "load_dotenv()\n",
                "\n",
                "# --- AWS Configuration ---\n",
                "AWS_ACCESS_KEY_ID = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
                "AWS_SECRET_ACCESS_KEY = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
                "AWS_REGION = os.getenv(\"AWS_REGION\", \"us-west-2\")\n",
                "\n",
                "# Validate required environment variables\n",
                "if not AWS_ACCESS_KEY_ID or not AWS_SECRET_ACCESS_KEY:\n",
                "    raise ValueError(\n",
                "        \"Missing required AWS credentials. Please ensure AWS_ACCESS_KEY_ID and \"\n",
                "        \"AWS_SECRET_ACCESS_KEY are set in your .env file or environment variables.\"\n",
                "    )\n",
                "\n",
                "# --- Bedrock Model Configuration ---\n",
                "# Using a stable Claude 3 Sonnet ID which is widely available in us-west-2\n",
                "BEDROCK_MODEL_ID = \"meta.llama3-8b-instruct-v1:0\"\n",
                "\n",
                "# --- ChromaDB Cloud Configuration ---\n",
                "# Sign up at https://trychroma.com to get your API Token\n",
                "CHROMA_API_KEY = \"\"\n",
                "CHROMA_TENANT = \"\"  # Usually 'default_tenant' for most users\n",
                "CHROMA_DATABASE = \"dev-demo\" # Usually 'default_database'\n",
                "CHROMA_COLLECTION_NAME = \"rag_collection\"\n",
                "\n",
                "# Apply Environment Variables for Boto3 (only if values are not None)\n",
                "if AWS_ACCESS_KEY_ID:\n",
                "    os.environ[\"AWS_ACCESS_KEY_ID\"] = AWS_ACCESS_KEY_ID\n",
                "if AWS_SECRET_ACCESS_KEY:\n",
                "    os.environ[\"AWS_SECRET_ACCESS_KEY\"] = AWS_SECRET_ACCESS_KEY\n",
                "if AWS_REGION:\n",
                "    os.environ[\"AWS_DEFAULT_REGION\"] = AWS_REGION\n",
                "\n",
                "print(\"Configuration Loaded.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "1. Initializing Boto3 Session...\n",
                        "   ✅ Bedrock Client Initialized successfully.\n",
                        "\n",
                        "2. Initializing ChromaDB Cloud Client...\n",
                        "   ✅ Connected to Chroma Cloud. Collection 'rag_collection' ready.\n",
                        "   ℹ️ Current Collection Count: 8228\n"
                    ]
                }
            ],
            "source": [
                "# Step 3: Initialize Clients\n",
                "import boto3\n",
                "import chromadb\n",
                "\n",
                "print(\"1. Initializing Boto3 Session...\")\n",
                "try:\n",
                "    session = boto3.Session(\n",
                "        aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
                "        aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
                "        region_name=AWS_REGION\n",
                "    )\n",
                "    bedrock_client = session.client(\"bedrock-runtime\")\n",
                "    print(\"   ✅ Bedrock Client Initialized successfully.\")\n",
                "except Exception as e:\n",
                "    print(f\"   ❌ Error initializing Bedrock: {e}\")\n",
                "\n",
                "print(\"\\n2. Initializing ChromaDB Cloud Client...\")\n",
                "try:\n",
                "    # Initialize CloudClient specifically for Chroma Cloud\n",
                "    chroma_client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
                "    \n",
                "    # Get or create the collection\n",
                "    collection = chroma_client.get_or_create_collection(name=CHROMA_COLLECTION_NAME)\n",
                "    print(f\"   ✅ Connected to Chroma Cloud. Collection '{CHROMA_COLLECTION_NAME}' ready.\")\n",
                "    print(f\"   ℹ️ Current Collection Count: {collection.count()}\")\n",
                "except Exception as e:\n",
                "    print(f\"   ❌ Error initializing ChromaDB Cloud: {e}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Phase 2: Data Ingestion & Chunking\n",
                "We will read text files from the `files/` directory, chunk them using LangChain's `RecursiveCharacterTextSplitter`, save the chunks to `files/chunked/`, and verify the output."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ℹ️ Directory exists: Richmond_Policies_Cleaned/chunked\n",
                        "Found 95 files in Richmond_Policies_Cleaned: ['jury_duty_and_subpoenas_policy.txt', 'endowment_spending_policy.txt', 'policy_on_pregnancy_childbirth_lactation_and_related_conditions_faculty_and_staff1.txt', 'password_policy.txt', 'policy_on_provision_of_financial_resources_to_students.txt'] ...\n"
                    ]
                }
            ],
            "source": [
                "# Step 4: Setup Directories\n",
                "import os\n",
                "\n",
                "SOURCE_DIR = \"Richmond_Policies_Cleaned\"\n",
                "CHUNKED_DIR = os.path.join(SOURCE_DIR, \"chunked\")\n",
                "\n",
                "# Create chunked directory if it doesn't exist\n",
                "if not os.path.exists(CHUNKED_DIR):\n",
                "    os.makedirs(CHUNKED_DIR)\n",
                "    print(f\"✅ Created directory: {CHUNKED_DIR}\")\n",
                "else:\n",
                "    print(f\"ℹ️ Directory exists: {CHUNKED_DIR}\")\n",
                "\n",
                "# List source files (excluding directory or hidden files)\n",
                "source_files = [f for f in os.listdir(SOURCE_DIR) if os.path.isfile(os.path.join(SOURCE_DIR, f)) and not f.startswith('.')]\n",
                "print(f\"Found {len(source_files)} files in {SOURCE_DIR}: {source_files[:5]} ...\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/Users/kyle-anthonyhay/Documents/CODE/Recature-Homework/Revature-Cognizant-Training-Exercises/December/venv/lib/python3.12/site-packages/keras/src/export/tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
                        "  if not hasattr(np, \"object\"):\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Starting chunking process...\n",
                        "\n",
                        "✅ jury_duty_and_subpoenas_policy.txt: Created 3 chunks.\n",
                        "✅ endowment_spending_policy.txt: Created 4 chunks.\n",
                        "✅ policy_on_pregnancy_childbirth_lactation_and_related_conditions_faculty_and_staff1.txt: Created 9 chunks.\n",
                        "✅ password_policy.txt: Created 11 chunks.\n",
                        "✅ policy_on_provision_of_financial_resources_to_students.txt: Created 13 chunks.\n",
                        "✅ course_level_policy.txt: Created 4 chunks.\n",
                        "✅ bereavement_leave_policy.txt: Created 5 chunks.\n",
                        "✅ policy_for_events_with_alcohol_on_campus.txt: Created 22 chunks.\n",
                        "✅ alcohol_and_drug_policy.txt: Created 53 chunks.\n",
                        "✅ policy_on_space_allocation_and_facilities_resources.txt: Created 34 chunks.\n",
                        "✅ multiple_donor_gifts_policy.txt: Created 7 chunks.\n",
                        "✅ general_data_privacy_regulation_notice.txt: Created 34 chunks.\n",
                        "✅ policy_for_employment_of_out_of_state_residents.txt: Created 13 chunks.\n",
                        "✅ non-retaliation_policy.txt: Created 4 chunks.\n",
                        "✅ office_assignment_policy.txt: Created 13 chunks.\n",
                        "✅ official_university_communications_policy.txt: Created 2 chunks.\n",
                        "✅ placement_of_student_art_installations.txt: Created 7 chunks.\n",
                        "✅ external_data_transfer_policy.txt: Created 6 chunks.\n",
                        "✅ policy_on_prohibiting_and_responding_to_sexual_harassment_and_sexual_misconduct_students.txt: Created 117 chunks.\n",
                        "✅ administrative_data_management_policy.txt: Created 29 chunks.\n",
                        "✅ inclement_weather_time_reporting_and_pay_policy.txt: Created 10 chunks.\n",
                        "✅ policy_on_political_campaign_activity_on_campus.txt: Created 26 chunks.\n",
                        "✅ intellectual_property_policy.txt: Created 49 chunks.\n",
                        "✅ policy_for_responding_to_allegations_of_research_misconduct.txt: Created 92 chunks.\n",
                        "✅ academic_integrity_monitoring.txt: Created 8 chunks.\n",
                        "✅ policy_on_prohibiting_and_responding_to_sex_discrimination_faculty_staff.txt: Created 71 chunks.\n",
                        "✅ museum_collections_management_policy.txt: Created 44 chunks.\n",
                        "✅ contract_management_policy.txt: Created 22 chunks.\n",
                        "✅ space_taxonomy.txt: Created 3 chunks.\n",
                        "✅ network_device_connectivity_policy.txt: Created 10 chunks.\n",
                        "✅ policy_prohibiting_discrimination.txt: Created 22 chunks.\n",
                        "✅ film_and_media_screening_policy.txt: Created 5 chunks.\n",
                        "✅ Statement_on_Free_Expression.txt: Created 5 chunks.\n",
                        "✅ policy_on_business_expenses_and_compensation.txt: Created 7 chunks.\n",
                        "✅ catering_minimums_policy.txt: Created 7 chunks.\n",
                        "✅ financial_aid_code_of_conduct.txt: Created 18 chunks.\n",
                        "✅ board_of_trustees_conflict_of_interest_policy.txt: Created 39 chunks.\n",
                        "✅ academic_progress_policy_as_bus_jepson.txt: Created 13 chunks.\n",
                        "✅ data_security_policy.txt: Created 38 chunks.\n",
                        "✅ academic_and_professional_preparation_requirements_for_faculty.txt: Created 10 chunks.\n",
                        "✅ information_security_policy.txt: Created 13 chunks.\n",
                        "✅ gifts_and_gratuities_policy.txt: Created 5 chunks.\n",
                        "✅ joint_ventures_policy.txt: Created 5 chunks.\n",
                        "✅ designation_of_emergency_personnel_policy.txt: Created 12 chunks.\n",
                        "✅ electronic_signature_policy.txt: Created 12 chunks.\n",
                        "✅ policy_on_creating_suspending_eliminating_programs.txt: Created 34 chunks.\n",
                        "✅ hazing_policy.txt: Created 17 chunks.\n",
                        "✅ hipaa_policy.txt: Created 37 chunks.\n",
                        "✅ policy_prohibiting_and_responding_to_discrimination_based_on_protected_status_faculty_staff.txt: Created 64 chunks.\n",
                        "✅ indirect_costs_recovery_policy.txt: Created 6 chunks.\n",
                        "✅ policy_prohibiting_firearms_on_campus.txt: Created 6 chunks.\n",
                        "✅ acceptable_use_policy.txt: Created 20 chunks.\n",
                        "✅ policy_prohibiting_and_responding_to_discrimination_based_on_protected_status_students.txt: Created 64 chunks.\n",
                        "✅ academic_credit_policy.txt: Created 41 chunks.\n",
                        "✅ faculty_phased_retirement_plan.txt: Created 10 chunks.\n",
                        "✅ policy_and_procedure_on_monetary_support_and_cash_donations.txt: Created 11 chunks.\n",
                        "✅ campus_ministry_policy.txt: Created 12 chunks.\n",
                        "✅ classroom_scheduling_policy.txt: Created 4 chunks.\n",
                        "✅ lock_and_key_management_policy.txt: Created 19 chunks.\n",
                        "✅ policy_on_prohibiting_and_responding_to_sexual_harassment_and_sexual_misconduct_faculty_staff.txt: Created 145 chunks.\n",
                        "✅ health_and_imunization_record_policy.txt: Created 5 chunks.\n",
                        "✅ early_retirement_plan_for_staff_and_faculty_with_a_continuing_appointment.txt: Created 24 chunks.\n",
                        "✅ compliance_training_policy.txt: Created 3 chunks.\n",
                        "✅ delegation_of_approval_authority_and_processing_responsibilities.txt: Created 13 chunks.\n",
                        "✅ cell_phone-policy.txt: Created 8 chunks.\n",
                        "✅ access_to_electronic_files_policy.txt: Created 13 chunks.\n",
                        "✅ gifts_prizes_and_awards_policy.txt: Created 11 chunks.\n",
                        "✅ delegation_of_contract_approval_and_signature_authority_policy.txt: Created 38 chunks.\n",
                        "✅ military_leave_policy.txt: Created 3 chunks.\n",
                        "✅ policy_on_policies.txt: Created 8 chunks.\n",
                        "✅ inclement_weather_policy.txt: Created 8 chunks.\n",
                        "✅ flexible_work_arrangement_policy.txt: Created 15 chunks.\n",
                        "✅ financial_conflict_of_interest_for_grant-funded_research.txt: Created 21 chunks.\n",
                        "✅ use_of_university_owned_houses.txt: Created 11 chunks.\n",
                        "✅ policy_on_prohibiting_and_responding_to_sex_discrimination_students.txt: Created 69 chunks.\n",
                        "✅ policy_on_campus_protests_and_demonstrations.txt: Created 18 chunks.\n",
                        "✅ appointment_of_endowed_chairs.txt: Created 14 chunks.\n",
                        "✅ effective_use_of_institutional_funds.txt: Created 9 chunks.\n",
                        "✅ electronic_card_access_policy.txt: Created 12 chunks.\n",
                        "✅ business_meals_policy.txt: Created 24 chunks.\n",
                        "✅ international_travel_policy.txt: Created 13 chunks.\n",
                        "✅ holiday_leave_policy.txt: Created 10 chunks.\n",
                        "✅ board_of_trustees_contract_approval_and_signature_authority.txt: Created 19 chunks.\n",
                        "✅ identity_and_access_management_policy.txt: Created 20 chunks.\n",
                        "✅ nepotism_and_personal_relationship_policy.txt: Created 4 chunks.\n",
                        "✅ policy_on_emeritus_status.txt: Created 3 chunks.\n",
                        "✅ cybersecurity_incident_response_policy.txt: Created 16 chunks.\n",
                        "✅ parental_leave_policy.txt: Created 11 chunks.\n",
                        "✅ additional_compensation_for_staff.txt: Created 15 chunks.\n",
                        "✅ photography_and_videography_policy.txt: Created 7 chunks.\n",
                        "✅ fringe_rate_policy.txt: Created 6 chunks.\n",
                        "✅ emergency_management_policy.txt: Created 18 chunks.\n",
                        "✅ policy_on_protecting_student_privacy_in_distance_education.txt: Created 6 chunks.\n",
                        "✅ benefits_for_10-month_staff_and_faculty_on_9-month_contracts.txt: Created 5 chunks.\n",
                        "✅ outdoor_grill_use_policy.txt: Created 8 chunks.\n",
                        "\n",
                        "🎉 Total Chunks Created: 1914\n"
                    ]
                }
            ],
            "source": [
                "# Step 5: Load, Chunk, and Save Files\n",
                "try:\n",
                "    # Try modern import first\n",
                "    from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
                "except ImportError:\n",
                "    # Fallback to legacy import\n",
                "    try:\n",
                "        from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
                "    except ImportError:\n",
                "        # Last resort\n",
                "        from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
                "\n",
                "# Initialize Splitter (prioritize sentence boundaries)\n",
                "text_splitter = RecursiveCharacterTextSplitter(\n",
                "    separators=[\". \", \"? \", \"! \", \"\\n\", \" \", \"\"],\n",
                "    chunk_size=1000,      # Characters (~200 tokens)\n",
                "    chunk_overlap=100,    # Overlap to maintain context\n",
                "    length_function=len,\n",
                "    is_separator_regex=False\n",
                ")\n",
                "\n",
                "total_chunks_processed = 0\n",
                "\n",
                "print(\"Starting chunking process...\\n\")\n",
                "\n",
                "for file_name in source_files:\n",
                "    file_path = os.path.join(SOURCE_DIR, file_name)\n",
                "    \n",
                "    try:\n",
                "        with open(file_path, 'r', encoding='utf-8') as f:\n",
                "            text = f.read()\n",
                "            \n",
                "        # Create Chunks\n",
                "        chunks = text_splitter.split_text(text)\n",
                "        \n",
                "        # Save each chunk with metadata in filename\n",
                "        # Format: ch{index}-{original_name}-{metadata}.txt\n",
                "        base_name = os.path.splitext(file_name)[0]\n",
                "        \n",
                "        for i, chunk_content in enumerate(chunks):\n",
                "            # Metadata example: length of chunk\n",
                "            metadata_str = f\"len{len(chunk_content)}\"\n",
                "            chunk_filename = f\"ch{i+1}-{base_name}-{metadata_str}.txt\"\n",
                "            chunk_path = os.path.join(CHUNKED_DIR, chunk_filename)\n",
                "            \n",
                "            with open(chunk_path, 'w', encoding='utf-8') as chunk_file:\n",
                "                chunk_file.write(chunk_content)\n",
                "                \n",
                "        print(f\"✅ {file_name}: Created {len(chunks)} chunks.\")\n",
                "        total_chunks_processed += len(chunks)\n",
                "        \n",
                "    except Exception as e:\n",
                "        print(f\"❌ Error processing {file_name}: {e}\")\n",
                "\n",
                "print(f\"\\n🎉 Total Chunks Created: {total_chunks_processed}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "--- Content of ch2-lock_and_key_management_policy-len394.txt ---\n",
                        "they are magnetically swiped, which then allows access. one card – the official university of richmond identification card. this card permits access to their\n",
                        "housing and many university services and facilities. operator key – any key that provides access to a limited number of locks within one building. outside contractors – companies hired by the university of richmond to provide a service.\n",
                        "\n",
                        "--- End of Sample ---\n"
                    ]
                }
            ],
            "source": [
                "# Step 6: Verify a Sample Chunk\n",
                "# Check one of the generated files to ensure content is correct\n",
                "if os.listdir(CHUNKED_DIR):\n",
                "    sample_chunk = os.listdir(CHUNKED_DIR)[0]\n",
                "    sample_path = os.path.join(CHUNKED_DIR, sample_chunk)\n",
                "    \n",
                "    print(f\"--- Content of {sample_chunk} ---\")\n",
                "    with open(sample_path, 'r', encoding='utf-8') as f:\n",
                "        print(f.read()[:500]) # Print first 500 chars\n",
                "    print(\"\\n--- End of Sample ---\")\n",
                "else:\n",
                "    print(\"No chunks found to verify.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Phase 3: Embeddings & Vector Store\n",
                "We will now read the chunked files we just created, generate embeddings (handled automatically by Chroma's default embedding function), and upsert them into the ChromaDB Cloud collection.\n",
                "\n",
                "> **Note:** We are using ChromaDB's default embedding model (`all-MiniLM-L6-v2`) which is built into the client. No extra API calls to Bedrock are needed for *embedding* in this setup, saving costs."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Found 2486 chunk files to process.\n",
                        "Prepared 2486 documents for embedding.\n"
                    ]
                }
            ],
            "source": [
                "# Step 7: Prepare Data for Embedding\n",
                "import uuid\n",
                "import re\n",
                "\n",
                "chunked_files = [f for f in os.listdir(CHUNKED_DIR) if f.endswith('.txt')]\n",
                "\n",
                "documents = []\n",
                "metadatas = []\n",
                "ids = []\n",
                "\n",
                "print(f\"Found {len(chunked_files)} chunk files to process.\")\n",
                "\n",
                "for file_name in chunked_files:\n",
                "    file_path = os.path.join(CHUNKED_DIR, file_name)\n",
                "    \n",
                "    try:\n",
                "        with open(file_path, 'r', encoding='utf-8') as f:\n",
                "            content = f.read()\n",
                "            \n",
                "        # Parse Metadata from Filename\n",
                "        # Format: ch{index}-{original_name}-{len}.txt\n",
                "        # Example: ch1-academic_policy-len495.txt\n",
                "        try:\n",
                "            name_no_ext = os.path.splitext(file_name)[0]\n",
                "            parts = name_no_ext.split('-')\n",
                "            \n",
                "            # 1. Chunk Part (first item, e.g., 'ch1')\n",
                "            chunk_part = int(parts[0].replace('ch', ''))\n",
                "            \n",
                "            # 2. Size (last item, e.g., 'len495')\n",
                "            size = int(parts[-1].replace('len', ''))\n",
                "            \n",
                "            # 3. File Name (everything in between)\n",
                "            original_filename = \"-\".join(parts[1:-1])\n",
                "            \n",
                "            meta = {\n",
                "                \"source\": file_name,\n",
                "                \"file_name\": original_filename,\n",
                "                \"chunk_part\": chunk_part,\n",
                "                \"size\": size\n",
                "            }\n",
                "        except Exception as e:\n",
                "            # Fallback if naming convention doesn't match\n",
                "            print(f\"⚠️ Metadata parse warning for {file_name}: {e}\")\n",
                "            meta = {\"source\": file_name}\n",
                "\n",
                "        # Add to lists\n",
                "        documents.append(content)\n",
                "        metadatas.append(meta)\n",
                "        ids.append(str(uuid.uuid4()))\n",
                "        \n",
                "    except Exception as e:\n",
                "        print(f\"Warning: Could not read {file_name}: {e}\")\n",
                "\n",
                "print(f\"Prepared {len(documents)} documents for embedding.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Upserting documents to ChromaDB Collection in batches...\n",
                        "   ✅ Processed batch 0 to 900\n",
                        "   ✅ Processed batch 900 to 1800\n",
                        "   ✅ Processed batch 1800 to 2486\n",
                        "\n",
                        "🎉 Successfully added all 2486 documents to ChromaDB!\n",
                        "Final Collection Count: 10714\n"
                    ]
                }
            ],
            "source": [
                "# Step 8: Add to ChromaDB (Embed & Upsert)\n",
                "# Batch size limit for Chroma is usually 1000 (we hit 1914!), so we must batch.\n",
                "print(\"Upserting documents to ChromaDB Collection in batches...\")\n",
                "\n",
                "BATCH_SIZE = 900  # Safe batch size\n",
                "total_docs = len(documents)\n",
                "\n",
                "try:\n",
                "    for i in range(0, total_docs, BATCH_SIZE):\n",
                "        batch_docs = documents[i : i + BATCH_SIZE]\n",
                "        batch_metas = metadatas[i : i + BATCH_SIZE]\n",
                "        batch_ids = ids[i : i + BATCH_SIZE]\n",
                "        \n",
                "        collection.add(\n",
                "            documents=batch_docs,\n",
                "            metadatas=batch_metas,\n",
                "            ids=batch_ids\n",
                "        )\n",
                "        print(f\"   ✅ Processed batch {i} to {min(i+BATCH_SIZE, total_docs)}\")\n",
                "        \n",
                "    print(f\"\\n🎉 Successfully added all {total_docs} documents to ChromaDB!\")\n",
                "    print(f\"Final Collection Count: {collection.count()}\")\n",
                "    \n",
                "except Exception as e:\n",
                "    print(f\"❌ Error adding to ChromaDB: {e}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Querying ChromaDB for: 'What is the alcohol policy?'...\n",
                        "\n",
                        "[Result 1]\n",
                        "   File: alcohol_and_drug_policy\n",
                        "   Part: 7\n",
                        "   Size: 973\n",
                        "   Snippet: . refusal by an employee to comply with the applicable requirements may\n",
                        "be grounds for immediate dis...\n",
                        "\n",
                        "[Result 2]\n",
                        "   File: alcohol_and_drug_policy\n",
                        "   Part: 7\n",
                        "   Size: 973\n",
                        "   Snippet: . refusal by an employee to comply with the applicable requirements may\n",
                        "be grounds for immediate dis...\n",
                        "\n",
                        "[Result 3]\n",
                        "   File: alcohol_and_drug_policy\n",
                        "   Part: 7\n",
                        "   Size: 973\n",
                        "   Snippet: . refusal by an employee to comply with the applicable requirements may\n",
                        "be grounds for immediate dis...\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "# Step 9: Verify Embedding with a Test Query\n",
                "# We will perform a simple similarity search (no LLM yet) to see if we get relevant chunks.\n",
                "\n",
                "query_text = \"What is the alcohol policy?\"  # Replace with a relevant question for your data\n",
                "\n",
                "print(f\"Querying ChromaDB for: '{query_text}'...\\n\")\n",
                "\n",
                "results = collection.query(\n",
                "    query_texts=[query_text],\n",
                "    n_results=3 # Get top 3 matches\n",
                ")\n",
                "\n",
                "if results['documents']:\n",
                "    for i, doc in enumerate(results['documents'][0]):\n",
                "        meta = results['metadatas'][0][i]\n",
                "        print(f\"[Result {i+1}]\")\n",
                "        print(f\"   File: {meta.get('file_name', 'Unknown')}\")\n",
                "        print(f\"   Part: {meta.get('chunk_part', '?')}\")\n",
                "        print(f\"   Size: {meta.get('size', '?')}\")\n",
                "        print(f\"   Snippet: {doc[:100]}...\\n\")\n",
                "else:\n",
                "    print(\"No results found. Check if documents were added correctly.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Phase 4: Retrieval & Generation\n",
                "We implement the custom retrieval logical (with distince threshold filtering) and connect it to AWS Bedrock for the final answer generation."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Step 10: Custom Retrieval Function\n",
                "def retrieve_documents(query, n_results=5, threshold=1.5, filter_by=None):\n",
                "    \"\"\"\n",
                "    Retrieve relevant documents with distance threshold filtering.\n",
                "    \n",
                "    Args:\n",
                "        query: The search query string\n",
                "        n_results: Max results to return initially\n",
                "        threshold: Max distance (lower = more strict match). \n",
                "                   For Cosine distance: 0 is identical, 1 is orthogonal, 2 is opposite.\n",
                "                   Typical good matches are < 1.0 depending on embedding model.\n",
                "        filter_by: Metadata filter dict (optional)\n",
                "    \n",
                "    Returns:\n",
                "        List of dicts: {text, source, distance}\n",
                "    \"\"\"\n",
                "    # Query Chroma\n",
                "    results = collection.query(\n",
                "        query_texts=[query],\n",
                "        n_results=n_results,\n",
                "        where=filter_by,\n",
                "        include=[\"documents\", \"metadatas\", \"distances\"]\n",
                "    )\n",
                "    \n",
                "    docs = []\n",
                "    \n",
                "    # Check if we got results\n",
                "    if results['documents'] and results['documents'][0]:\n",
                "        # Iterate through the first query's results\n",
                "        for text, meta, dist in zip(\n",
                "            results['documents'][0],\n",
                "            results['metadatas'][0],\n",
                "            results['distances'][0]\n",
                "        ):\n",
                "            # Filter by threshold\n",
                "            if dist <= threshold:\n",
                "                docs.append({\n",
                "                    \"text\": text,\n",
                "                    \"source\": meta.get(\"source\", \"unknown\"),\n",
                "                    \"distance\": dist\n",
                "                })\n",
                "                \n",
                "    print(f\"✅ Retrieved {len(docs)} documents (Threshold: {threshold})\")\n",
                "    return docs"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "# VALID_CATEGORIES removed - using direct query without category routing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Step 11: RAG Generation Function (Bedrock) - Single Step Query\n",
                "from langchain_aws import ChatBedrock\n",
                "\n",
                "# Fix for newer LangChain versions (v0.1+)\n",
                "try:\n",
                "    from langchain_core.prompts import PromptTemplate\n",
                "    from langchain_core.runnables import RunnablePassthrough\n",
                "    from langchain_core.output_parsers import StrOutputParser\n",
                "except ImportError:\n",
                "    # Fallback for older versions\n",
                "    from langchain.prompts import PromptTemplate\n",
                "    from langchain.schema.runnable import RunnablePassthrough\n",
                "    from langchain.schema.output_parser import StrOutputParser\n",
                "\n",
                "# Initialize LLM\n",
                "llm = ChatBedrock(\n",
                "    model_id=BEDROCK_MODEL_ID,\n",
                "    client=bedrock_client,\n",
                "    model_kwargs={\"max_tokens\": 1000, \"temperature\": 0.1}\n",
                ")\n",
                "\n",
                "def generate_answer(query):\n",
                "    # Direct query without category routing - single step\n",
                "    print(f\"🔍 Querying: {query}\")\n",
                "    \n",
                "    # Retrieve documents directly (no metadata filter)\n",
                "    relevant_docs = retrieve_documents(query, n_results=5, threshold=1.2, filter_by=None)\n",
                "    print(f\"🔍 Retrieved {len(relevant_docs)} documents\")\n",
                "    \n",
                "    if not relevant_docs:\n",
                "        return \"I could not find any relevant information to answer your question.\"\n",
                "    \n",
                "    # Format Context\n",
                "    context_text = \"\\n\\n\".join([f\"[Source: {d['source']}]\\n{d['text']}\" for d in relevant_docs])\n",
                "    \n",
                "    # Construct Prompt\n",
                "    prompt_template = \"\"\"\n",
                "    Human: You are a concise and direct assistant. Use the following pieces of context to answer the question at the end.\n",
                "    \n",
                "    Rules for answering:\n",
                "    1. Be extremely concise.\n",
                "    2. Do NOT use bullet points or numbered lists. \n",
                "    3. Provide a single, direct paragraph.\n",
                "    4. If you don't know the answer, just say that you don't know.\n",
                "\n",
                "    Context:\n",
                "    {context}\n",
                "\n",
                "    Question: {question}\n",
                "\n",
                "    Assistant:\"\"\"\n",
                "    \n",
                "    prompt = PromptTemplate(\n",
                "        template=prompt_template, \n",
                "        input_variables=[\"context\", \"question\"]\n",
                "    )\n",
                "    \n",
                "    # Invoke LLM\n",
                "    final_prompt = prompt.format(context=context_text, question=query)\n",
                "    response = llm.invoke(final_prompt)\n",
                "    \n",
                "    return response.content"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "❓ Question: What is the policy regarding drug usage?\n",
                        "\n",
                        "🔍 Querying: What is the policy regarding drug usage?\n",
                        "✅ Retrieved 5 documents (Threshold: 1.2)\n",
                        "🔍 Retrieved 5 documents\n",
                        "💡 Answer:\n",
                        "The university policy prohibits the unauthorized manufacture, distribution, and possession of controlled substances, including cocaine, ecstasy, and LSD, which are punishable by severe penalties. Additionally, students and employees who violate state and federal laws may be referred for criminal prosecution and are subject to disciplinary action, with sanctions ranging from substance education to permanent separation.\n"
                    ]
                }
            ],
            "source": [
                "# Step 12: Final Test\n",
                "query = \"What is the policy regarding drug usage?\"\n",
                "\n",
                "print(f\"❓ Question: {query}\\n\")\n",
                "\n",
                "answer = generate_answer(query)\n",
                "\n",
                "print(\"💡 Answer:\")\n",
                "print(answer)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
