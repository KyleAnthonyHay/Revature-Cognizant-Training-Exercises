{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sentio+ RAG Pipeline\n",
        "\n",
        "A straightforward implementation of the RAG pipeline for app review insights.\n",
        "\n",
        "**Components:**\n",
        "1. Configuration\n",
        "2. ChromaDB vector store\n",
        "3. LLM setup (AWS Bedrock or OpenAI-compatible)\n",
        "4. Data ingestion with chunking\n",
        "5. RAG query pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hayde\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Configuration loaded\n",
            "   Notebook dir: C:\\Users\\hayde\\OneDrive\\Documents\\GitHub\\sentio-plus\\Project\n",
            "   Project root: C:\\Users\\hayde\\OneDrive\\Documents\\GitHub\\sentio-plus\n",
            "   ChromaDB path: C:\\Users\\hayde\\OneDrive\\Documents\\GitHub\\sentio-plus\\Project\\chroma_data_v2\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "from langchain.tools import tool\n",
        "from langchain.agents import create_agent\n",
        "from langchain.messages import HumanMessage, AIMessage, SystemMessage\n",
        "from langgraph.checkpoint.memory import InMemorySaver\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "\n",
        "# ==================== CONFIGURATION ====================\n",
        "# NOTE: This notebook mirrors the settings in src/config/settings.py\n",
        "# Update both when making changes to maintain consistency.\n",
        "\n",
        "# Resolve paths relative to notebook location (app/)\n",
        "NOTEBOOK_DIR = Path(\".\").resolve()\n",
        "PROJECT_ROOT = NOTEBOOK_DIR.parent  # sentio-plus/\n",
        "\n",
        "# LLM Configuration\n",
        "LLM_PROVIDER = \"bedrock\"  # \"bedrock\" or \"openai\"\n",
        "LLM_MODEL = \"anthropic.claude-3-sonnet-20240229-v1:0\"  # For Bedrock\n",
        "# LLM_MODEL = \"llama3.2\"  # For local Ollama\n",
        "LLM_BASE_URL = \"http://localhost:11434/v1\"  # For OpenAI-compatible (Ollama, LM Studio)\n",
        "LLM_API_KEY = os.getenv(\"LLM_API_KEY\", \"not-needed\")  # Local models don't need this\n",
        "LLM_TEMPERATURE = 0.1\n",
        "LLM_MAX_TOKENS = 1000\n",
        "\n",
        "# AWS Configuration (only needed for Bedrock)\n",
        "AWS_REGION = os.getenv(\"AWS_REGION\", \"us-west-2\")\n",
        "AWS_ACCESS_KEY_ID = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
        "AWS_SECRET_ACCESS_KEY = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
        "\n",
        "# ChromaDB Configuration\n",
        "CHROMA_CLIENT_TYPE = \"persistent\"  # \"persistent\", \"http\", or \"cloud\"\n",
        "# Use a fresh directory to avoid conflicts with corrupted/incompatible old data\n",
        "# The old chroma_data/ was created with ChromaDB <1.4 and is incompatible with 1.4+\n",
        "CHROMA_PERSIST_PATH = NOTEBOOK_DIR / \"chroma_data_v2\"  # Fresh directory for ChromaDB 1.4+\n",
        "CHROMA_HOST = \"localhost\"  # For HTTP client\n",
        "CHROMA_PORT = 8000  # For HTTP client\n",
        "CHROMA_CLOUD_API_KEY = os.getenv(\"CHROMA_API_KEY\")  # For cloud client\n",
        "CHROMA_CLOUD_TENANT = os.getenv(\"CHROMA_TENANT\")  # For cloud client\n",
        "CHROMA_CLOUD_DATABASE = os.getenv(\"CHROMA_DATABASE\")  # For cloud client\n",
        "CHROMA_COLLECTION_NAME = \"sentio_reviews\"\n",
        "\n",
        "# Retrieval Configuration\n",
        "RETRIEVAL_TOP_K = 5\n",
        "RETRIEVAL_THRESHOLD = 1.2  # Cosine distance: 0=identical, 2=opposite\n",
        "\n",
        "# Chunking Configuration\n",
        "CHUNK_SIZE = 500\n",
        "CHUNK_OVERLAP = 100\n",
        "\n",
        "# Data paths\n",
        "DATA_DIR = PROJECT_ROOT / \"data\"\n",
        "CSV_FILE = DATA_DIR / \"processed\" / \"sentio_plus_rag_ready.csv\"\n",
        "INGEST_LIMIT = 1000  # Set to None for all rows\n",
        "\n",
        "print(\"‚úÖ Configuration loaded\")\n",
        "print(f\"   Notebook dir: {NOTEBOOK_DIR}\")\n",
        "print(f\"   Project root: {PROJECT_ROOT}\")\n",
        "print(f\"   ChromaDB path: {CHROMA_PERSIST_PATH}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Initialize ChromaDB Vector Store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ ChromaDB initialized (persistent): C:\\Users\\hayde\\OneDrive\\Documents\\GitHub\\sentio-plus\\Project\\chroma_data_v2\n",
            "   Collection: sentio_reviews\n",
            "   Documents in collection: 1,071\n"
          ]
        }
      ],
      "source": [
        "import uuid\n",
        "import chromadb\n",
        "from chromadb.config import Settings as ChromaSettings\n",
        "\n",
        "# Initialize ChromaDB client based on client type\n",
        "if CHROMA_CLIENT_TYPE == \"persistent\":\n",
        "    # Create persistent directory\n",
        "    CHROMA_PERSIST_PATH.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    chroma_client = chromadb.PersistentClient(\n",
        "        path=str(CHROMA_PERSIST_PATH),\n",
        "        settings=ChromaSettings(anonymized_telemetry=False),\n",
        "    )\n",
        "    print(f\"‚úÖ ChromaDB initialized (persistent): {CHROMA_PERSIST_PATH}\")\n",
        "    \n",
        "elif CHROMA_CLIENT_TYPE == \"http\":\n",
        "    chroma_client = chromadb.HttpClient(\n",
        "        host=CHROMA_HOST,\n",
        "        port=CHROMA_PORT,\n",
        "        settings=ChromaSettings(anonymized_telemetry=False),\n",
        "    )\n",
        "    print(f\"‚úÖ ChromaDB initialized (http): {CHROMA_HOST}:{CHROMA_PORT}\")\n",
        "    \n",
        "elif CHROMA_CLIENT_TYPE == \"cloud\":\n",
        "    if not CHROMA_CLOUD_API_KEY or not CHROMA_CLOUD_TENANT or not CHROMA_CLOUD_DATABASE:\n",
        "        raise ValueError(\"CHROMA_API_KEY, CHROMA_TENANT, and CHROMA_DATABASE required for cloud client.\")\n",
        "    \n",
        "    chroma_client = chromadb.CloudClient(\n",
        "        tenant=CHROMA_CLOUD_TENANT,\n",
        "        database=CHROMA_CLOUD_DATABASE,\n",
        "        api_key=CHROMA_CLOUD_API_KEY,\n",
        "        settings=ChromaSettings(anonymized_telemetry=False),\n",
        "    )\n",
        "    print(f\"‚úÖ ChromaDB initialized (cloud): {CHROMA_CLOUD_TENANT}/{CHROMA_CLOUD_DATABASE}\")\n",
        "    \n",
        "else:\n",
        "    raise ValueError(f\"Unknown CHROMA_CLIENT_TYPE: {CHROMA_CLIENT_TYPE}. Use 'persistent', 'http', or 'cloud'.\")\n",
        "\n",
        "# Get or create collection\n",
        "collection = chroma_client.get_or_create_collection(\n",
        "    name=CHROMA_COLLECTION_NAME,\n",
        "    metadata={\"hnsw:space\": \"cosine\"},\n",
        ")\n",
        "\n",
        "print(f\"   Collection: {CHROMA_COLLECTION_NAME}\")\n",
        "print(f\"   Documents in collection: {collection.count():,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Initialize LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ LLM initialized: Bedrock / anthropic.claude-3-sonnet-20240229-v1:0\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "\n",
        "# Initialize LLM based on provider\n",
        "if LLM_PROVIDER == \"bedrock\":\n",
        "    import boto3\n",
        "    from langchain_aws import ChatBedrock\n",
        "    \n",
        "    if not AWS_ACCESS_KEY_ID or not AWS_SECRET_ACCESS_KEY:\n",
        "        raise ValueError(\"AWS credentials required for Bedrock. Set AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY.\")\n",
        "    \n",
        "    bedrock_client = boto3.client(\n",
        "        \"bedrock-runtime\",\n",
        "        region_name=AWS_REGION,\n",
        "        aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
        "        aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
        "    )\n",
        "    \n",
        "    llm = ChatBedrock(\n",
        "        model_id=LLM_MODEL,\n",
        "        client=bedrock_client,\n",
        "        model_kwargs={\n",
        "            \"temperature\": LLM_TEMPERATURE,\n",
        "            \"max_tokens\": LLM_MAX_TOKENS,\n",
        "        },\n",
        "    )\n",
        "    print(f\"‚úÖ LLM initialized: Bedrock / {LLM_MODEL}\")\n",
        "    \n",
        "else:  # OpenAI-compatible (Ollama, LM Studio, vLLM, OpenAI)\n",
        "    from langchain_openai import ChatOpenAI\n",
        "    \n",
        "    llm = ChatOpenAI(\n",
        "        base_url=LLM_BASE_URL,\n",
        "        model=LLM_MODEL,\n",
        "        api_key=LLM_API_KEY,\n",
        "        temperature=LLM_TEMPERATURE,\n",
        "        max_tokens=LLM_MAX_TOKENS,\n",
        "    )\n",
        "    print(f\"‚úÖ LLM initialized: OpenAI-compatible / {LLM_MODEL}\")\n",
        "    print(f\"   Base URL: {LLM_BASE_URL}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LLM test response: hello\n"
          ]
        }
      ],
      "source": [
        "# Quick test\n",
        "response = llm.invoke(\"Say 'hello' and nothing else.\")\n",
        "print(f\"LLM test response: {response.content}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Prompt Templates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Prompt templates defined\n"
          ]
        }
      ],
      "source": [
        "# Source selection prompt - used to pre-filter relevant apps\n",
        "SOURCE_SELECTION_PROMPT = \"\"\"You are given a list of app names from product reviews.\n",
        "Return ONLY the names of the apps that are relevant to the question.\n",
        "If none are relevant, return \"none\".\n",
        "Do not explain your reasoning.\n",
        "\n",
        "Apps:\n",
        "{sources}\n",
        "\n",
        "Question:\n",
        "{query}\n",
        "\n",
        "Return format (comma-separated):\n",
        "app1, app2, app3\"\"\"\n",
        "\n",
        "# RAG prompt - used to generate answers from retrieved context\n",
        "RAG_PROMPT = \"\"\"You are a helpful assistant analyzing product reviews. Use the following review excerpts to answer the question.\n",
        "\n",
        "Rules:\n",
        "1. Be concise and direct.\n",
        "2. Base your answer ONLY on the provided reviews.\n",
        "3. If the reviews don't contain relevant information, say so.\n",
        "4. Mention specific apps when relevant.\n",
        "5. Include sentiment (positive/negative) when discussing features.\n",
        "\n",
        "Reviews:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Answer:\"\"\"\n",
        "\n",
        "print(\"‚úÖ Prompt templates defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Data Ingestion\n",
        "\n",
        "Load CSV data, chunk it, and add to ChromaDB."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hayde\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\export\\tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
            "  if not hasattr(np, \"object\"):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\hayde\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n",
            "‚úÖ CSV file found: C:\\Users\\hayde\\OneDrive\\Documents\\GitHub\\sentio-plus\\data\\processed\\sentio_plus_rag_ready.csv\n",
            "   Loaded 50,000 rows\n",
            "   Columns: ['review_id', 'app_id', 'app_name', 'category', 'rating', 'review_date', 'helpful_count', 'content_rating', 'app_avg_score', 'downloads', 'text_length', 'enriched_text']\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Check if CSV exists\n",
        "if not CSV_FILE.exists():\n",
        "    print(f\"‚ùå CSV file not found: {CSV_FILE}\")\n",
        "    print(\"   Please ensure the data file exists before running ingestion.\")\n",
        "else:\n",
        "    print(f\"‚úÖ CSV file found: {CSV_FILE}\")\n",
        "    \n",
        "    # Load data\n",
        "    df = pd.read_csv(CSV_FILE)\n",
        "    print(f\"   Loaded {len(df):,} rows\")\n",
        "    print(f\"   Columns: {list(df.columns)}\")\n",
        "    \n",
        "    # Show sample\n",
        "    df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ingest_csv_to_chroma(\n",
        "    df,\n",
        "    collection,\n",
        "    text_column=\"enriched_text\",\n",
        "    id_column=\"review_id\",\n",
        "    chunk_size=CHUNK_SIZE,\n",
        "    chunk_overlap=CHUNK_OVERLAP,\n",
        "    batch_size=500,\n",
        "    limit=None,\n",
        "    clear_existing=False,\n",
        "):\n",
        "    \"\"\"\n",
        "    Ingest DataFrame into ChromaDB with chunking.\n",
        "    \n",
        "    Args:\n",
        "        df: DataFrame with review data\n",
        "        collection: ChromaDB collection\n",
        "        text_column: Column containing review text\n",
        "        id_column: Column containing review IDs\n",
        "        chunk_size: Max characters per chunk\n",
        "        chunk_overlap: Overlap between chunks\n",
        "        batch_size: Documents per batch\n",
        "        limit: Max rows to process (None = all)\n",
        "        clear_existing: Whether to clear collection first\n",
        "    \n",
        "    Returns:\n",
        "        Dict with ingestion stats\n",
        "    \"\"\"\n",
        "    global chroma_client\n",
        "    \n",
        "    # Validate columns\n",
        "    required_cols = [text_column, id_column, \"app_name\", \"category\", \"rating\", \"review_date\", \"helpful_count\"]\n",
        "    missing = [col for col in required_cols if col not in df.columns]\n",
        "    if missing:\n",
        "        raise ValueError(f\"Missing columns: {missing}\")\n",
        "    \n",
        "    # Drop rows with missing text\n",
        "    df = df.dropna(subset=[text_column]).copy()\n",
        "    print(f\"After dropna: {len(df):,} rows\")\n",
        "    \n",
        "    # Apply limit\n",
        "    if limit:\n",
        "        df = df.head(limit)\n",
        "        print(f\"Limited to: {len(df):,} rows\")\n",
        "    \n",
        "    # Clear collection if requested\n",
        "    if clear_existing:\n",
        "        chroma_client.delete_collection(collection.name)\n",
        "        collection = chroma_client.get_or_create_collection(\n",
        "            name=CHROMA_COLLECTION_NAME,\n",
        "            metadata={\"hnsw:space\": \"cosine\"},\n",
        "        )\n",
        "        print(\"üóëÔ∏è Collection cleared\")\n",
        "    \n",
        "    # Initialize text splitter\n",
        "    splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=chunk_size,\n",
        "        chunk_overlap=chunk_overlap,\n",
        "    )\n",
        "    \n",
        "    # Prepare documents\n",
        "    all_chunks = []\n",
        "    all_metadatas = []\n",
        "    all_ids = []\n",
        "    \n",
        "    for _, row in df.iterrows():\n",
        "        # Extract review text (after header if present)\n",
        "        enriched_text = row[text_column]\n",
        "        review_text = enriched_text.split(\"USER REVIEW: \")[-1] if \"USER REVIEW: \" in str(enriched_text) else enriched_text\n",
        "        \n",
        "        # Split into chunks\n",
        "        chunks = splitter.split_text(str(review_text))\n",
        "        \n",
        "        # Create metadata and IDs for each chunk\n",
        "        review_id = int(row[id_column])\n",
        "        base_id = f\"com.{row['app_name']}_{review_id}\"\n",
        "        \n",
        "        for i, chunk in enumerate(chunks):\n",
        "            all_chunks.append(chunk)\n",
        "            all_metadatas.append({\n",
        "                \"review_id\": review_id,\n",
        "                \"app_name\": row[\"app_name\"],\n",
        "                \"category\": row[\"category\"],\n",
        "                \"rating\": int(row[\"rating\"]),\n",
        "                \"date\": str(row[\"review_date\"]),\n",
        "                \"helpful_count\": int(row[\"helpful_count\"]),\n",
        "                \"chunk_index\": i,\n",
        "                \"total_chunks\": len(chunks),\n",
        "            })\n",
        "            all_ids.append(f\"{base_id}_chunk_{i}\")\n",
        "    \n",
        "    print(f\"Prepared {len(all_chunks):,} chunks from {len(df):,} reviews\")\n",
        "    \n",
        "    # Add to collection in batches\n",
        "    total_added = 0\n",
        "    for i in range(0, len(all_chunks), batch_size):\n",
        "        end = min(i + batch_size, len(all_chunks))\n",
        "        \n",
        "        collection.add(\n",
        "            documents=all_chunks[i:end],\n",
        "            metadatas=all_metadatas[i:end],\n",
        "            ids=all_ids[i:end],\n",
        "        )\n",
        "        \n",
        "        total_added += (end - i)\n",
        "        print(f\"   ‚úÖ Batch {i}:{end} added ({total_added:,}/{len(all_chunks):,})\")\n",
        "    \n",
        "    print(f\"\\n‚úÖ Ingestion complete!\")\n",
        "    print(f\"   Rows processed: {len(df):,}\")\n",
        "    print(f\"   Chunks added: {total_added:,}\")\n",
        "    print(f\"   Collection count: {collection.count():,}\")\n",
        "    \n",
        "    return {\n",
        "        \"rows_processed\": len(df),\n",
        "        \"chunks_added\": total_added,\n",
        "        \"collection_count\": collection.count(),\n",
        "        \"collection\": collection,\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Collection already has 1,071 documents.\n",
            "   Set clear_existing=True to re-ingest.\n"
          ]
        }
      ],
      "source": [
        "# Run ingestion (skip if collection already has data)\n",
        "if collection.count() == 0:\n",
        "    print(\"Collection is empty. Running ingestion...\\n\")\n",
        "    result = ingest_csv_to_chroma(\n",
        "        df=df,\n",
        "        collection=collection,\n",
        "        limit=INGEST_LIMIT,\n",
        "        clear_existing=False,\n",
        "    )\n",
        "    # Update collection reference if it was recreated\n",
        "    collection = result.get(\"collection\", collection)\n",
        "else:\n",
        "    print(f\"‚úÖ Collection already has {collection.count():,} documents.\")\n",
        "    print(\"   Set clear_existing=True to re-ingest.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Helper functions defined\n"
          ]
        }
      ],
      "source": [
        "def get_all_app_names(collection):\n",
        "    \"\"\"Get all unique app names from the collection.\"\"\"\n",
        "    results = collection.get(include=[\"metadatas\"])\n",
        "    return {meta.get(\"app_name\") for meta in results[\"metadatas\"] if meta.get(\"app_name\")}\n",
        "\n",
        "\n",
        "def query_collection(\n",
        "    collection,\n",
        "    query_text,\n",
        "    n_results=RETRIEVAL_TOP_K,\n",
        "    threshold=RETRIEVAL_THRESHOLD,\n",
        "    where=None,\n",
        "):\n",
        "    \"\"\"\n",
        "    Query the collection with distance threshold filtering.\n",
        "    \n",
        "    Args:\n",
        "        collection: ChromaDB collection\n",
        "        query_text: Search query\n",
        "        n_results: Max results to return\n",
        "        threshold: Max distance (lower = stricter). Cosine: 0=identical, 2=opposite.\n",
        "        where: Optional metadata filter\n",
        "    \n",
        "    Returns:\n",
        "        List of dicts with 'text', 'metadata', 'distance'\n",
        "    \"\"\"\n",
        "    results = collection.query(\n",
        "        query_texts=[query_text],\n",
        "        n_results=n_results,\n",
        "        where=where,\n",
        "        include=[\"documents\", \"metadatas\", \"distances\"],\n",
        "    )\n",
        "    \n",
        "    docs = []\n",
        "    if results[\"documents\"] and results[\"documents\"][0]:\n",
        "        for text, meta, dist in zip(\n",
        "            results[\"documents\"][0],\n",
        "            results[\"metadatas\"][0],\n",
        "            results[\"distances\"][0],\n",
        "        ):\n",
        "            if dist <= threshold:\n",
        "                docs.append({\n",
        "                    \"text\": text,\n",
        "                    \"metadata\": meta,\n",
        "                    \"distance\": dist,\n",
        "                })\n",
        "    \n",
        "    return docs\n",
        "\n",
        "\n",
        "def select_relevant_sources(question, app_names):\n",
        "    \"\"\"\n",
        "    Use LLM to select relevant app sources for a question.\n",
        "    \n",
        "    Args:\n",
        "        question: User question\n",
        "        app_names: Set of available app names\n",
        "    \n",
        "    Returns:\n",
        "        List of relevant app names (empty if none relevant)\n",
        "    \"\"\"\n",
        "    if not app_names:\n",
        "        return []\n",
        "    \n",
        "    prompt = SOURCE_SELECTION_PROMPT.format(\n",
        "        sources=\", \".join(sorted(app_names)),\n",
        "        query=question,\n",
        "    )\n",
        "    \n",
        "    response = llm.invoke(prompt)\n",
        "    content = response.content\n",
        "    \n",
        "    # Remove any thinking tags (for reasoning models)\n",
        "    content = re.sub(r\"<think>.*?</think>\", \"\", content, flags=re.DOTALL)\n",
        "    \n",
        "    # Parse comma-separated response\n",
        "    sources = [s.strip() for s in content.split(\",\")]\n",
        "    \n",
        "    # Return empty if \"none\"\n",
        "    if len(sources) == 1 and sources[0].lower() == \"none\":\n",
        "        return []\n",
        "    \n",
        "    return sources\n",
        "\n",
        "\n",
        "def format_context(docs):\n",
        "    \"\"\"Format retrieved documents into context string.\"\"\"\n",
        "    formatted = []\n",
        "    for doc in docs:\n",
        "        meta = doc[\"metadata\"]\n",
        "        app = meta.get(\"app_name\", \"Unknown\")\n",
        "        rating = meta.get(\"rating\", \"?\")\n",
        "        text = doc[\"text\"]\n",
        "        formatted.append(f\"[{app} - {rating}‚òÖ]\\n{text}\")\n",
        "    return \"\\n\\n\".join(formatted)\n",
        "\n",
        "\n",
        "print(\"‚úÖ Helper functions defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. RAG Query Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ RAG query function defined\n"
          ]
        }
      ],
      "source": [
        "@tool\n",
        "def rag_query(\n",
        "    question,\n",
        "    filter_by_source=True,\n",
        "    top_k=RETRIEVAL_TOP_K,\n",
        "    threshold=RETRIEVAL_THRESHOLD,\n",
        "):\n",
        "    \"\"\"\n",
        "    Answer a question using RAG.\n",
        "    \n",
        "    Args:\n",
        "        question: User question\n",
        "        filter_by_source: Whether to use LLM to pre-filter sources\n",
        "        top_k: Number of documents to retrieve\n",
        "        threshold: Distance threshold for filtering\n",
        "    \n",
        "    Returns:\n",
        "        Dict with answer, sources, num_docs, and selected_sources\n",
        "    \"\"\"\n",
        "    print(f\"üìù Question: {question}\")\n",
        "    print(f\"   Filter by source: {filter_by_source}\")\n",
        "    print()\n",
        "    \n",
        "    # Step 1: Optionally filter sources using LLM\n",
        "    metadata_filter = None\n",
        "    selected_sources = []\n",
        "    \n",
        "    if filter_by_source:\n",
        "        app_names = get_all_app_names(collection)\n",
        "        selected_sources = select_relevant_sources(question, app_names)\n",
        "        \n",
        "        if selected_sources:\n",
        "            metadata_filter = {\"app_name\": {\"$in\": selected_sources}}\n",
        "            print(f\"üéØ Filtering by apps: {selected_sources}\")\n",
        "        else:\n",
        "            print(\"üîç No specific app filter applied\")\n",
        "    \n",
        "    # Step 2: Retrieve relevant documents\n",
        "    docs = query_collection(\n",
        "        collection=collection,\n",
        "        query_text=question,\n",
        "        n_results=top_k,\n",
        "        threshold=threshold,\n",
        "        where=metadata_filter,\n",
        "    )\n",
        "    \n",
        "    print(f\"üìö Retrieved {len(docs)} documents\")\n",
        "    \n",
        "    # Step 3: Handle no results\n",
        "    if not docs:\n",
        "        return {\n",
        "            \"answer\": \"I couldn't find any relevant reviews to answer your question.\",\n",
        "            \"sources\": [],\n",
        "            \"num_docs\": 0,\n",
        "            \"selected_sources\": selected_sources,\n",
        "        }\n",
        "    \n",
        "    # Step 4: Format context\n",
        "    context = format_context(docs)\n",
        "\n",
        "    return context\n",
        "    \n",
        "    '''\n",
        "    # Step 5: Generate answer\n",
        "    prompt = RAG_PROMPT.format(context=context, question=question)\n",
        "    response = llm.invoke(prompt)\n",
        "    answer = response.content\n",
        "    \n",
        "    # Step 6: Extract unique sources\n",
        "    sources = list({doc[\"metadata\"].get(\"app_name\", \"unknown\") for doc in docs})\n",
        "    \n",
        "    print(f\"üì± Sources used: {sources}\")\n",
        "    print()\n",
        "    \n",
        "    return {\n",
        "        \"answer\": answer,\n",
        "        \"sources\": sources,\n",
        "        \"num_docs\": len(docs),\n",
        "        \"selected_sources\": selected_sources,\n",
        "    }\n",
        "    '''\n",
        "\n",
        "print(\"‚úÖ RAG query function defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Test Queries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìù Question: What is Google Wallet?\n",
            "   Filter by source: True\n",
            "\n",
            "üéØ Filtering by apps: ['Google Wallet']\n",
            "üìö Retrieved 5 documents\n",
            "content='Based on the search results, Google Wallet appears to be a digital wallet app from Google that allows users to store payment cards like credit/debit cards and gift cards on their mobile device to make contactless payments. However, the reviews indicate some frustrations with limited functionality compared to competitors like Apple Wallet, issues adding certain card types like insurance cards, and occasional glitches or errors.\\n\\nIn summary, Google Wallet is a mobile payment and digital wallet service from Google, but the reviews suggest it may have some limitations and usability issues compared to alternatives. The core functionality is storing payment cards for contactless mobile payments, but users seem to want more capabilities to store other card types like IDs, insurance cards, etc.' additional_kwargs={'usage': {'prompt_tokens': 965, 'completion_tokens': 153, 'cache_read_input_tokens': 0, 'cache_write_input_tokens': 0, 'total_tokens': 1118}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'} response_metadata={'usage': {'prompt_tokens': 965, 'completion_tokens': 153, 'cache_read_input_tokens': 0, 'cache_write_input_tokens': 0, 'total_tokens': 1118}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0', 'model_provider': 'bedrock', 'model_name': 'anthropic.claude-3-sonnet-20240229-v1:0'} name='conversational_agent' id='lc_run--019bbaf4-ac6a-7092-a8dd-702668e330f3-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 965, 'output_tokens': 153, 'total_tokens': 1118, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}\n",
            "content='The last question you asked was \"What is Google Wallet?\"' additional_kwargs={'usage': {'prompt_tokens': 1127, 'completion_tokens': 16, 'cache_read_input_tokens': 0, 'cache_write_input_tokens': 0, 'total_tokens': 1143}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'} response_metadata={'usage': {'prompt_tokens': 1127, 'completion_tokens': 16, 'cache_read_input_tokens': 0, 'cache_write_input_tokens': 0, 'total_tokens': 1143}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0', 'model_provider': 'bedrock', 'model_name': 'anthropic.claude-3-sonnet-20240229-v1:0'} name='conversational_agent' id='lc_run--019bbaf4-ba0e-7202-bb19-d1ba9301ce92-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 1127, 'output_tokens': 16, 'total_tokens': 1143, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}\n"
          ]
        }
      ],
      "source": [
        "#agent = init_chat_model(BEDROCK_MODEL)\n",
        "\n",
        "config = {\n",
        "    \"configurable\": {\n",
        "        \"thread_id\": \"user-1\"\n",
        "    }\n",
        "}\n",
        "\n",
        "tools = [rag_query]\n",
        "\n",
        "agent = create_agent(\n",
        "    model=llm,\n",
        "    tools=tools,\n",
        "    checkpointer=InMemorySaver(),  # Enables memory\n",
        "    name=\"conversational_agent\"\n",
        ")\n",
        "\n",
        "\n",
        "result = agent.invoke({\n",
        "    \"messages\": [\n",
        "        (\"user\", input())\n",
        "    ]\n",
        "},\n",
        "config=config)\n",
        "\n",
        "print(result[\"messages\"][-1])\n",
        "\n",
        "\n",
        "result = agent.invoke({\n",
        "    \"messages\": [\n",
        "        (\"user\", \"What was the last question?\")\n",
        "    ]\n",
        "},\n",
        "config=config)\n",
        "\n",
        "print(result[\"messages\"][-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìù Question: What are common complaints about apps?\n",
            "   Filter by source: True\n",
            "\n",
            "üîç No specific app filter applied\n",
            "üìö Retrieved 5 documents\n",
            "üì± Sources used: ['Google Wallet', 'Western Union Send Money Now']\n",
            "\n",
            "============================================================\n",
            "üí¨ ANSWER:\n",
            "============================================================\n",
            "Based on the provided reviews, some common complaints about apps include:\n",
            "\n",
            "1. Usability issues (negative sentiment):\n",
            "   - \"Painful to use\"\n",
            "   - \"Intermittent dropouts without explanation\"\n",
            "   - \"Seemingly completely random 'verification' requirements\"\n",
            "   - \"The app crashes often during the process\"\n",
            "\n",
            "2. Technical issues/glitches (negative sentiment):\n",
            "   - \"It is too glitchy now\"\n",
            "   - \"Slow on launch, and usually requires a relaunch because it just loads forever\"\n",
            "   - \"The app needs technical attention\"\n",
            "\n",
            "3. Functionality issues (negative sentiment):\n",
            "   - \"The apps been pretty much useless\"\n",
            "   - \"It's saying I haven't passed security?\"\n",
            "   - \"Constantly robs you of loyalty points everytime you go to use them\"\n",
            "   - \"I've had friends have their money get stuck processing\"\n",
            "\n",
            "4. Lack of reliability/trust (negative sentiment):\n",
            "   - \"I'm afraid to rely on it for sending/receiving money\"\n",
            "   - \"Everything just got a bit worse\"\n",
            "\n",
            "The reviews mention specific apps like Google Wallet and Western Union Send Money Now, highlighting issues related to usability, technical glitches, functionality problems, and lack of reliability in these apps.\n"
          ]
        }
      ],
      "source": [
        "# Test query 1: General question\n",
        "result = rag_query(\"What do people like about apps?\")\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"üí¨ ANSWER:\")\n",
        "print(\"=\" * 60)\n",
        "print(result[\"answer\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìù Question: What are common complaints about apps?\n",
            "   Filter by source: True\n",
            "\n",
            "üîç No specific app filter applied\n",
            "üìö Retrieved 5 documents\n",
            "üì± Sources used: ['Google Wallet', 'Western Union Send Money Now']\n",
            "\n",
            "============================================================\n",
            "üí¨ ANSWER:\n",
            "============================================================\n",
            "Based on the provided reviews, some common complaints about apps include:\n",
            "\n",
            "1. Poor performance and glitches (negative)\n",
            "   - \"Terrible app. Painful to use, intermittent dropouts without explanation\"\n",
            "   - \"App was great over a year ago. Transactions were seamless. It is too glitchy now.\"\n",
            "   - \"The app crashes often during the process\"\n",
            "\n",
            "2. Security and verification issues (negative)\n",
            "   - \"seemingly completely random \"verification\" requirements\"\n",
            "   - \"it's saying I haven't passed security?\"\n",
            "\n",
            "3. Difficulty using loyalty points/rewards (negative)\n",
            "   - \"Constantly robs you of loyalty points everytime you go to use them.\"\n",
            "   - \"194 wu points and still being charged!\"\n",
            "\n",
            "4. Slow or unresponsive (negative)\n",
            "   - \"Slow on launch, and usually requires a relaunch because it just loads forever.\"\n",
            "\n",
            "5. Money getting stuck or not processed correctly (negative)\n",
            "   - \"I've had friends have their money get stuck processing\"\n",
            "   - \"I'm afraid to rely on it for sending/receiving money.\"\n",
            "\n",
            "The reviews mention specific apps like Google Wallet and Western Union Send Money Now when discussing these complaints.\n"
          ]
        }
      ],
      "source": [
        "# Test query 2: Specific topic\n",
        "result = rag_query(\"What are common complaints about apps?\")\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"üí¨ ANSWER:\")\n",
        "print(\"=\" * 60)\n",
        "print(result[\"answer\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìù Question: What do people think about navigation apps?\n",
            "   Filter by source: False\n",
            "\n",
            "üìö Retrieved 5 documents\n",
            "üì± Sources used: ['Google Wallet']\n",
            "\n",
            "============================================================\n",
            "üí¨ ANSWER:\n",
            "============================================================\n",
            "The provided reviews do not contain any relevant information about navigation apps. The reviews are focused on discussing the Google Wallet app and its features related to storing payment cards, tickets, and passes. There are no mentions of navigation or navigation apps in these reviews.\n"
          ]
        }
      ],
      "source": [
        "# Test query 3: App-specific (without source filtering)\n",
        "result = rag_query(\n",
        "    \"What do people think about navigation apps?\",\n",
        "    filter_by_source=False,\n",
        ")\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"üí¨ ANSWER:\")\n",
        "print(\"=\" * 60)\n",
        "print(result[\"answer\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Collection Stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Collection Statistics\n",
            "========================================\n",
            "Total documents: 1,071\n",
            "Unique apps: 2\n",
            "Unique categories: 1\n",
            "\n",
            "Categories: ['Finance']\n",
            "\n",
            "Apps: ['Google Wallet', 'Western Union Send Money Now']\n"
          ]
        }
      ],
      "source": [
        "def get_collection_stats(collection):\n",
        "    \"\"\"Get statistics about the collection.\"\"\"\n",
        "    results = collection.get(include=[\"metadatas\"])\n",
        "    metadatas = results[\"metadatas\"]\n",
        "    \n",
        "    categories = {meta.get(\"category\") for meta in metadatas if meta.get(\"category\")}\n",
        "    apps = {meta.get(\"app_name\") for meta in metadatas if meta.get(\"app_name\")}\n",
        "    \n",
        "    return {\n",
        "        \"total_documents\": collection.count(),\n",
        "        \"unique_categories\": len(categories),\n",
        "        \"unique_apps\": len(apps),\n",
        "        \"categories\": sorted(categories) if len(categories) <= 20 else f\"{len(categories)} categories\",\n",
        "        \"apps\": sorted(apps) if len(apps) <= 20 else f\"{len(apps)} apps\",\n",
        "    }\n",
        "\n",
        "\n",
        "stats = get_collection_stats(collection)\n",
        "print(\"üìä Collection Statistics\")\n",
        "print(\"=\" * 40)\n",
        "print(f\"Total documents: {stats['total_documents']:,}\")\n",
        "print(f\"Unique apps: {stats['unique_apps']}\")\n",
        "print(f\"Unique categories: {stats['unique_categories']}\")\n",
        "print()\n",
        "print(\"Categories:\", stats['categories'])\n",
        "print()\n",
        "print(\"Apps:\", stats['apps'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Interactive Query (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìù Question: Which apps have the best reviews?\n",
            "   Filter by source: True\n",
            "\n",
            "üîç No specific app filter applied\n",
            "üìö Retrieved 5 documents\n",
            "üì± Sources used: ['Google Wallet', 'Western Union Send Money Now']\n",
            "\n",
            "============================================================\n",
            "üí¨ ANSWER:\n",
            "============================================================\n",
            "Based solely on the provided reviews, none of the apps mentioned (Google Wallet, Western Union Send Money Now) have positive reviews. All of the reviews are negative, criticizing various issues with the apps such as poor functionality, errors, and problems using features like loyalty points. The reviews do not contain any information suggesting that any of these apps have the \"best\" reviews.\n",
            "\n",
            "üìä Documents used: 5\n",
            "üì± Sources: ['Google Wallet', 'Western Union Send Money Now']\n"
          ]
        }
      ],
      "source": [
        "# Interactive query cell - modify the question and run\n",
        "QUESTION = \"Which apps have the best reviews?\"\n",
        "FILTER_BY_SOURCE = True\n",
        "\n",
        "result = rag_query(QUESTION, filter_by_source=FILTER_BY_SOURCE)\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"üí¨ ANSWER:\")\n",
        "print(\"=\" * 60)\n",
        "print(result[\"answer\"])\n",
        "print()\n",
        "print(f\"üìä Documents used: {result['num_docs']}\")\n",
        "print(f\"üì± Sources: {result['sources']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Utility: Clear Collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uncomment to clear the collection and re-ingest\n",
        "# chroma_client.delete_collection(CHROMA_COLLECTION_NAME)\n",
        "# collection = chroma_client.get_or_create_collection(\n",
        "#     name=CHROMA_COLLECTION_NAME,\n",
        "#     metadata={\"hnsw:space\": \"cosine\"},\n",
        "# )\n",
        "# print(f\"üóëÔ∏è Collection cleared. Count: {collection.count()}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
